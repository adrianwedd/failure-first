---
import BaseLayout from '../layouts/BaseLayout.astro';
import PageHeader from '../components/PageHeader.astro';
import StatGrid from '../components/StatGrid.astro';
import WarningBox from '../components/WarningBox.astro';
import LinkButton from '../components/LinkButton.astro';
---

<BaseLayout title="Failure-First Embodied AI | Research Framework">
  <PageHeader
    title="Failure-First Embodied AI"
    tagline="A research framework for characterizing how embodied AI systems fail"
  />

  <section>
    <h2>Philosophy</h2>
    <p>
      This project inverts traditional AI safety evaluation: instead of measuring task success,
      we study <strong>how systems fail, degrade, and recover</strong> under adversarial pressure.
    </p>
    <p>
      Failure is not an edge case—it's the <strong>primary object of study</strong>.
    </p>
  </section>

  <StatGrid items={[
    { value: "51,000+", label: "Adversarial Scenarios" },
    { value: "661", label: "Failure Classes" },
    { value: "19", label: "Domains Covered" },
    { value: "51+", label: "Models Evaluated" },
  ]} />

  <section>
    <h2>What We Study</h2>
    <div class="card">
      <h3>Recursive Failures</h3>
      <p>How does one failure cascade into others? What breaks first?</p>
    </div>
    <div class="card">
      <h3>Contextual Failures</h3>
      <p>When do systems confuse instruction hierarchies or mix contexts?</p>
    </div>
    <div class="card">
      <h3>Interactional Failures</h3>
      <p>How do multi-agent scenarios amplify individual weaknesses?</p>
    </div>
    <div class="card">
      <h3>Temporal Failures</h3>
      <p>What degrades across stateful episodes? Memory consistency? Context drift?</p>
    </div>
    <div class="card">
      <h3>Recovery Failures</h3>
      <p>Can systems recognize and recover from their own mistakes? Do they admit uncertainty?</p>
    </div>
  </section>

  <WarningBox>
    <p>
      This is <strong>defensive AI safety research</strong>. All adversarial content is
      pattern-level description for testing, not operational instructions for exploitation.
      Similar to penetration testing in cybersecurity—we study vulnerabilities to build better defenses.
    </p>
  </WarningBox>

  <section>
    <h2>Adversarial Technique Taxonomy</h2>
    <p>Our research classifies observed attack patterns into structural categories:</p>

    <div class="card">
      <h3>Single-Agent Patterns</h3>
      <p><strong>Constraint Shadowing (CSC)</strong> &mdash; Local instructions shadow global safety constraints.</p>
      <p><strong>Contextual Debt Accumulation (CDA)</strong> &mdash; Accumulated context creates implicit authority the model fails to verify.</p>
      <p><strong>Probabilistic Gradient (PCG)</strong> &mdash; Gradual escalation that stays below per-turn detection thresholds.</p>
      <p><strong>Temporal Authority Mirage (TAM)</strong> &mdash; False claims about prior conversation states or future permissions.</p>
      <p><strong>Multi-turn Cascades</strong> &mdash; 3&ndash;7 pattern combinations across conversation turns, with compound failure rates.</p>
    </div>

    <div class="card">
      <h3>Multi-Agent Patterns</h3>
      <p>Discovered through analysis of 1,497 posts on <a href="https://www.moltbook.com" target="_blank" rel="noopener">Moltbook</a>, an AI-agent-only social network:</p>
      <p><strong>Environment Shaping</strong> &mdash; Manipulating the information environment that agents read, rather than prompting them directly.</p>
      <p><strong>Narrative Constraint Erosion</strong> &mdash; Philosophical or emotional framing that socially penalizes safety compliance.</p>
      <p><strong>Emergent Authority Hierarchies</strong> &mdash; Platform influence (engagement metrics, token economies) creating real authority without fabrication.</p>
      <p><strong>Cross-Agent Prompt Injection</strong> &mdash; Executable content embedded in social posts, consumed by agents that read the feed.</p>
      <p><strong>Identity Fluidity Normalization</strong> &mdash; Shared vocabulary around context resets and session discontinuity that enables identity manipulation.</p>
    </div>

    <div class="card">
      <h3>Embodied-Specific Patterns</h3>
      <p><strong>Irreversibility Gap</strong> &mdash; Cloud agents can be reset; physical agents leave marks. Safety constraints must account for irreversible actions.</p>
      <p><strong>Context Reset Mid-Task</strong> &mdash; What happens when an agent controlling a physical system loses context during a kinematic sequence.</p>
      <p><strong>Sensor-Actuator Desync</strong> &mdash; Safety interlocks that depend on sensor state which has drifted from reality.</p>
    </div>
  </section>

  <section>
    <h2>Core Principles</h2>
    <ul class="principles">
      <li>Pattern-level only, never operational</li>
      <li>Defensive purpose, always</li>
      <li>No real-world targeting of deployed systems</li>
      <li>Recovery mechanisms measured, not just failures</li>
      <li>Schema-enforced, rigorously validated</li>
      <li>Transparency over secrecy</li>
    </ul>
  </section>

  <section>
    <h2>Multi-Agent Research</h2>
    <p>
      Our latest research extends beyond single-model jailbreaks to study
      <strong>how AI agents influence each other</strong> in live multi-agent environments.
      We analyzed 1,497 posts from <a href="https://www.moltbook.com" target="_blank" rel="noopener">Moltbook</a>, an AI-agent-only social network, classifying them against
      34+ attack patterns using both regex and LLM semantic analysis.
    </p>
    <div class="card">
      <h3>Key Finding</h3>
      <p>
        Multi-agent attacks work through <strong>environment shaping</strong>, not direct prompts.
        Posts become part of other agents' context. Upvotes amplify reach. Token economies create
        incentive structures. The highest-engagement post (316K+ upvotes) matched 7 attack classes
        via semantic analysis but zero via keyword detection&mdash;narrative attacks operate below
        the surface of traditional safety filters.
      </p>
    </div>
    <div class="card">
      <h3>34+ Attack Classes Across 7 Categories</h3>
      <p>
        Expanded from 10 initial patterns to a full taxonomy covering: authority &amp; identity,
        narrative &amp; philosophical erosion, social dynamics, technical exploitation,
        temporal manipulation, systemic failures, and format evasion. LLM classification
        discovered that philosophical constraint erosion and narrative framing are the
        dominant attack vectors&mdash;appearing in 20% of high-engagement posts.
      </p>
    </div>
    <div class="card">
      <h3>Active Experiments Underway</h3>
      <p>
        Moving from passive observation to controlled experimentation. Five experiments testing
        framing effects, context sensitivity, defensive inoculation, authority signals, and
        narrative propagation. All conducted transparently as a safety researcher.
      </p>
      <p style="margin-top: 0.75rem;">
        <a href="/research/moltbook/" class="link-button" style="font-size: 0.875rem;">Read the full research &rarr;</a>
      </p>
    </div>
  </section>

  <section>
    <h2>What You Get</h2>
    <div class="card">
      <h3>Datasets</h3>
      <p>
        Curated adversarial scenarios in structured JSONL format.
        Coverage: humanoid robotics, warehouse systems, medical devices, collaborative manufacturing.
      </p>
    </div>
    <div class="card">
      <h3>Schemas</h3>
      <p>
        Versioned JSON Schemas for single-agent, multi-agent, and episode formats.
        Ensures consistency and enables validation.
      </p>
    </div>
    <div class="card">
      <h3>Evaluation Tools</h3>
      <p>
        Schema validators, safety linters, benchmark runners (CLI + HTTP),
        and scoring reports measuring refusal quality and recovery mechanisms.
      </p>
    </div>
    <div class="card">
      <h3>Safety Infrastructure</h3>
      <p>
        Automated CI validation, manual review gates, and contribution guidelines
        ensuring all content remains pattern-level and defensively purposed.
      </p>
    </div>
  </section>

  <section>
    <h2>Get Started</h2>
    <div class="links">
      <LinkButton href="https://github.com/adrianwedd/failure-first" text="View on GitHub" external />
      <LinkButton href="https://github.com/adrianwedd/failure-first/blob/main/README.md" text="Read the README" external />
      <LinkButton href="https://github.com/adrianwedd/failure-first/blob/main/DESIGN_CHARTER.md" text="Design Charter" external />
      <LinkButton href="https://github.com/adrianwedd/failure-first/blob/main/IMPLEMENTATION_PLAN.md" text="Implementation Plan" external />
    </div>
  </section>

  <section>
    <h2>Quick Start</h2>
    <p>Clone the repository and validate datasets:</p>
    <pre><code>git clone https://github.com/adrianwedd/failure-first.git
cd failure-first
pip install -r requirements-dev.txt
make validate  # Schema validation
make lint      # Safety checks</code></pre>
  </section>
</BaseLayout>

---
import ContentLayout from '../../layouts/ContentLayout.astro';
import PageHeader from '../../components/PageHeader.astro';
import KeyMetrics from '../../components/KeyMetrics.astro';
import ResearchCategoryCard from '../../components/ResearchCategoryCard.astro';

// Research categories with their studies
const categories = [
  {
    title: "Jailbreak Archaeology",
    description: "Historical analysis of attack evolution from 2022-2025. 64 scenarios across 6 eras, tested against 8 foundation models.",
    icon: "archaeology",
    color: "warning",
    count: 1,
    links: [
      { label: "Archaeology Dataset", href: "/research/jailbreak-archaeology/" },
    ],
  },
  {
    title: "Multi-Agent Research",
    description: "How AI agents influence each other in multi-agent environments. Environment shaping, narrative erosion, and emergent authority hierarchies.",
    icon: "multiagent",
    color: "primary",
    count: 2,
    links: [
      { label: "Moltbook Analysis", href: "/research/moltbook/" },
      { label: "Multi-Agent Scenarios", href: "/research/multi-agent/" },
    ],
  },
  {
    title: "Attack Pattern Analysis",
    description: "Taxonomy of adversarial techniques and how models respond to them. From single-turn exploits to multi-turn cascades.",
    icon: "taxonomy",
    color: "danger",
    count: 3,
    links: [
      { label: "Attack Taxonomy", href: "/research/attack-taxonomy/" },
      { label: "Model Vulnerability", href: "/research/model-vulnerability/" },
      { label: "Compression Findings", href: "/research/compression/" },
    ],
  },
  {
    title: "Defense Mechanisms",
    description: "How models resist adversarial attacks. Format/content separation, refusal patterns, and recovery mechanisms.",
    icon: "defense",
    color: "success",
    count: 2,
    links: [
      { label: "Defense Patterns", href: "/research/defense-patterns/" },
      { label: "Recovery Taxonomy", href: "/research/recovery-taxonomy/" },
    ],
  },
  {
    title: "Failure Taxonomies",
    description: "Classification systems for understanding how AI systems fail. Recursive, contextual, interactional, and temporal failures.",
    icon: "methodology",
    color: "tertiary",
    count: 2,
    links: [
      { label: "Failure Modes", href: "/research/failure-modes/" },
      { label: "Humanoid Safety", href: "/research/humanoid-safety/" },
    ],
  },
  {
    title: "Prompt Injection Testing",
    description: "12 calibrated honeypot pages testing AI agent susceptibility to indirect prompt injection. From visible baselines to expert-level multi-vector attacks.",
    icon: "taxonomy",
    color: "danger",
    count: 12,
    links: [
      { label: "Test Suite", href: "/research/prompt-injection/" },
    ],
  },
  {
    title: "Policy Brief Series",
    description: "19 deep research reports on embodied AI safety: regulation, standards, technical analysis, and policy recommendations.",
    icon: "policy",
    color: "secondary",
    count: 19,
    links: [
      { label: "All Policy Reports", href: "/research/reports/" },
    ],
  },
];

// All individual research pages for the complete listing
const researchPages = [
  {
    title: "Jailbreak Archaeology",
    href: "/research/jailbreak-archaeology/",
    description: "Historical analysis of attack evolution from 2022-2025. 64 scenarios across 6 eras.",
    status: "complete",
    category: "Jailbreak Archaeology",
  },
  {
    title: "Moltbook: Multi-Agent Attack Surface",
    href: "/research/moltbook/",
    description: "Empirical analysis of 1,497 AI agent interactions on an agent-only social network.",
    status: "active",
    category: "Multi-Agent",
  },
  {
    title: "Multi-Agent Failure Scenarios",
    href: "/research/multi-agent/",
    description: "How multiple actors create failure conditions that single-agent testing misses.",
    status: "active",
    category: "Multi-Agent",
  },
  {
    title: "Model Vulnerability Findings",
    href: "/research/model-vulnerability/",
    description: "How model size, architecture, and training affect vulnerability to adversarial attacks.",
    status: "active",
    category: "Attack Patterns",
  },
  {
    title: "Humanoid Robotics Safety",
    href: "/research/humanoid-safety/",
    description: "Safety analysis of humanoid robots across 15+ research dimensions.",
    status: "active",
    category: "Failure Taxonomies",
  },
  {
    title: "Compression Tournament Findings",
    href: "/research/compression/",
    description: "Methodology lessons from three iterations of adversarial prompt compression.",
    status: "complete",
    category: "Attack Patterns",
  },
  {
    title: "Defense Pattern Analysis",
    href: "/research/defense-patterns/",
    description: "How models resist adversarial attacks: the format/content separation pattern.",
    status: "complete",
    category: "Defense Mechanisms",
  },
  {
    title: "Attack Pattern Taxonomy",
    href: "/research/attack-taxonomy/",
    description: "79 attack techniques classified across 7 categories.",
    status: "complete",
    category: "Attack Patterns",
  },
  {
    title: "Failure Mode Taxonomy",
    href: "/research/failure-modes/",
    description: "Recursive, contextual, interactional, and temporal failure classifications.",
    status: "complete",
    category: "Failure Taxonomies",
  },
  {
    title: "Recovery Mechanisms",
    href: "/research/recovery-taxonomy/",
    description: "How AI systems recover (or fail to recover) from failure states.",
    status: "complete",
    category: "Defense Mechanisms",
  },
  {
    title: "Research Methodology",
    href: "/research/methodology/",
    description: "Our approach to adversarial AI safety research and benchmarking.",
    status: "complete",
    category: "Methodology",
  },
  {
    title: "Prompt Injection Test Suite",
    href: "/research/prompt-injection/",
    description: "12 honeypot pages testing AI agent susceptibility to indirect prompt injection across 4 difficulty tiers.",
    status: "active",
    category: "Prompt Injection",
  },
];

const statusColors: Record<string, string> = {
  active: "var(--recovery-active)",
  draft: "var(--failure-warning)",
  complete: "var(--recovery-stable)",
};

const statusLabels: Record<string, string> = {
  active: "Active",
  draft: "Draft",
  complete: "Published",
};
---

<ContentLayout
  title="Research | Failure-First"
  description="Research hub for failure-first AI safety studies. Multi-agent analysis, attack taxonomies, defense patterns, and failure modes."
  breadcrumbs={[{ label: "Research" }]}
>
  <PageHeader
    title="Research"
    tagline="How AI systems fail, degrade, and recover"
  />

  <section>
    <p>
      Our research characterizes AI failure patterns through adversarial testing.
      We study how systems break down under pressure, how failures cascade across
      agents, and what makes recovery possible.
    </p>
  </section>

  <!-- Key Metrics (Compact) -->
  <KeyMetrics compact />

  <!-- Research Categories -->
  <h2>Research Areas</h2>
  <p>Explore findings by category:</p>
  <div class="category-grid">
    {categories.map((category) => (
      <ResearchCategoryCard
        title={category.title}
        description={category.description}
        icon={category.icon}
        color={category.color}
        links={category.links}
        count={category.count}
      />
    ))}
  </div>

  <!-- All Studies -->
  <h2>All Studies</h2>
  <div class="research-grid">
    {researchPages.map((page) => (
      <a href={page.href} class="research-card card">
        <div class="research-card-header">
          <h3>{page.title}</h3>
          <span class="status-pill" style={`--pill-color: ${statusColors[page.status]}`}>
            {statusLabels[page.status]}
          </span>
        </div>
        <p>{page.description}</p>
        <span class="category-tag">{page.category}</span>
      </a>
    ))}
  </div>

  <!-- Cross-Cutting Insights -->
  <section class="insights-section">
    <h2>Five Cross-Cutting Insights</h2>
    <p>
      Our research converges on five key findings that cut across all studies
      and inform policy recommendations:
    </p>

    <div class="insight-grid">
      <div class="insight card">
        <h3>1. The Semantic-Kinetic Gap</h3>
        <p>
          VLA models collapse the traditional robotics stack (Sense-Plan-Act) into a single
          neural network. A linguistic misunderstanding becomes a physical hazard with no
          intermediate controller to catch the error. This is the master vulnerability for
          embodied AI.
        </p>
      </div>

      <div class="insight card">
        <h3>2. Binary Phase Transitions</h3>
        <p>
          Jailbreak success exhibits binary behavior: 0% compliance when attacks fail,
          100% persistence when they succeed. There is no gradual degradation. Once
          "captured," models remain compromised.
        </p>
      </div>

      <div class="insight card">
        <h3>3. Multi-Agent Failures Are Emergent</h3>
        <p>
          Failures in multi-agent systems are emergent, not additive. Cascade depth,
          semantic drift velocity, and consensus instability create failure modes that
          single-agent testing cannot detect.
        </p>
      </div>

      <div class="insight card">
        <h3>4. The Regulatory Danger Zone</h3>
        <p>
          2026-2029 is the critical window: EU AI Act compliance deadlines, mass humanoid
          deployment, and regulatory bodies without embodied AI evaluation capabilities
          all converge.
        </p>
      </div>

      <div class="insight card">
        <h3>5. Defense Requires Distrust</h3>
        <p>
          Effective defense architectures treat AI as an "untrusted oracle" whose outputs
          are suggestions, not commands. The correct default is to assume the AI will fail
          and design containment.
        </p>
      </div>
    </div>
  </section>

  <!-- Academic Resources -->
  <section class="academic-section">
    <h2>For Researchers</h2>
    <div class="academic-links">
      <a href="/cite/" class="academic-card card">
        <h3>Cite This Work</h3>
        <p>BibTeX citations and reference formats for academic papers.</p>
      </a>
      <a href="/research/methodology/" class="academic-card card">
        <h3>Methodology</h3>
        <p>Detailed research approach, data collection, and validation methods.</p>
      </a>
      <a href="/framework/datasets/" class="academic-card card">
        <h3>Datasets</h3>
        <p>Access structured datasets for reproducible research.</p>
      </a>
    </div>
  </section>
</ContentLayout>

<style>
  .category-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 1rem;
    margin-top: 1.5rem;
    margin-bottom: 3rem;
  }

  .research-grid {
    display: grid;
    gap: 1rem;
    margin-top: 1.5rem;
  }

  .research-card {
    display: block;
    text-decoration: none;
    border-bottom: none;
  }

  .research-card:hover {
    border-bottom: none;
  }

  .research-card-header {
    display: flex;
    align-items: flex-start;
    justify-content: space-between;
    gap: 0.75rem;
  }

  .research-card h3 {
    margin: 0;
    font-size: 1.0625rem;
  }

  .research-card p {
    margin-top: 0.5rem;
    margin-bottom: 0.5rem;
    font-size: 0.875rem;
  }

  .category-tag {
    font-family: 'JetBrains Mono', monospace;
    font-size: 0.625rem;
    color: var(--fg-muted);
    text-transform: uppercase;
    letter-spacing: 0.04em;
  }

  .status-pill {
    flex-shrink: 0;
    font-family: 'JetBrains Mono', monospace;
    font-size: 0.625rem;
    font-weight: 500;
    text-transform: uppercase;
    letter-spacing: 0.06em;
    padding: 0.1875rem 0.5rem;
    border: 1px solid var(--pill-color);
    color: var(--pill-color);
    border-radius: 3px;
    white-space: nowrap;
  }

  .academic-section {
    margin-top: 3rem;
    padding-top: 2rem;
    border-top: 1px solid var(--border-subtle);
  }

  .academic-links {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 1rem;
    margin-top: 1.5rem;
  }

  .academic-card {
    display: block;
    text-decoration: none;
    border-bottom: none;
  }

  .academic-card:hover {
    border-bottom: none;
  }

  .academic-card h3 {
    margin: 0 0 0.5rem 0;
    font-size: 1rem;
  }

  .academic-card p {
    margin: 0;
    font-size: 0.8125rem;
    color: var(--fg-muted);
  }

  .insights-section {
    margin-top: 3rem;
    padding-top: 2rem;
    border-top: 1px solid var(--border-subtle);
  }

  .insight-grid {
    display: grid;
    gap: 1rem;
    margin-top: 1.5rem;
  }

  .insight {
    border-left: 3px solid var(--accent-primary);
  }

  .insight h3 {
    margin-top: 0;
    font-size: 1rem;
    color: var(--accent-primary);
  }

  .insight p {
    margin-bottom: 0;
    font-size: 0.875rem;
  }

  @media (max-width: 768px) {
    .category-grid {
      grid-template-columns: 1fr;
    }

    .academic-links {
      grid-template-columns: 1fr;
    }
  }
</style>

<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><!-- Primary Meta --><title>Daily Paper | Failure-First</title><meta name="description" content="One AI safety paper per day — curated, analyzed, and contextualized through the failure-first lens. Research reports, study guides, and audio overviews for each paper."><link rel="canonical" href="https://failurefirst.org/daily-paper/"><meta name="robots" content="index, follow"><meta name="author" content="Adrian Wedd"><meta name="language" content="English"><meta name="theme-color" content="#0a0a0a"><!-- Open Graph --><meta property="og:type" content="website"><meta property="og:title" content="Daily Paper | Failure-First"><meta property="og:description" content="One AI safety paper per day — curated, analyzed, and contextualized through the failure-first lens. Research reports, study guides, and audio overviews for each paper."><meta property="og:url" content="https://failurefirst.org/daily-paper/"><meta property="og:site_name" content="Failure-First Embodied AI"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://failurefirst.org/og-image.png"><meta property="og:image:alt" content="Daily Paper | Failure-First - Failure-First Embodied AI"><meta property="og:image:type" content="image/png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@failurefirstai"><meta name="twitter:creator" content="@adrianwedd"><meta name="twitter:title" content="Daily Paper | Failure-First"><meta name="twitter:description" content="One AI safety paper per day — curated, analyzed, and contextualized through the failure-first lens. Research reports, study guides, and audio overviews for each paper."><meta name="twitter:image" content="https://failurefirst.org/og-image.png"><meta name="twitter:image:alt" content="Daily Paper | Failure-First - Failure-First Embodied AI"><!-- Google Scholar Meta Tags (for research papers) --><!-- JSON-LD Structured Data --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Organization","name":"Failure-First Embodied AI","url":"https://failurefirst.org","logo":{"@type":"ImageObject","url":"https://failurefirst.org/og-image.png"},"sameAs":["https://github.com/adrianwedd/failure-first"],"contactPoint":{"@type":"ContactPoint","contactType":"Research Inquiries","url":"https://failurefirst.org/contact/"}}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"ResearchProject","name":"Failure-First Embodied AI","description":"A research framework for characterizing how embodied AI systems fail, degrade, and recover under adversarial pressure.","url":"https://failurefirst.org","sameAs":["https://github.com/adrianwedd/failure-first"],"author":{"@type":"Person","name":"Adrian Wedd"},"sponsor":{"@type":"Organization","name":"Failure-First Embodied AI","url":"https://failurefirst.org"}}</script><link rel="alternate" type="application/rss+xml" title="Failure-First Embodied AI" href="/rss.xml"><!-- Google Analytics (GA4) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-XXEW64L22D"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-XXEW64L22D');
    </script><link rel="stylesheet" href="/assets/_slug_.BV0HTfXU.css">
<style>.breadcrumbs[data-astro-cid-ilhxcym7]{margin-bottom:1.5rem;font-size:.8125rem;font-family:JetBrains Mono,monospace}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{list-style:none;display:flex;flex-wrap:wrap;gap:0;padding:0}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{color:var(--fg-muted)}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]:not(:last-child):after{content:"/";margin:0 .5rem;color:var(--fg-muted);opacity:.5}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--fg-muted);border-bottom:none}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{color:var(--accent-primary)}.breadcrumbs[data-astro-cid-ilhxcym7] span[data-astro-cid-ilhxcym7][aria-current=page]{color:var(--fg-dim)}
.series-description[data-astro-cid-7a6gb5fb]{color:var(--fg-dim);font-size:.9375rem;line-height:1.6;margin-top:1.25rem;margin-bottom:2rem;max-width:640px}.paper-list[data-astro-cid-7a6gb5fb]{display:grid;gap:1rem}.paper-card[data-astro-cid-7a6gb5fb]{display:block;text-decoration:none;border-bottom:none}.paper-card[data-astro-cid-7a6gb5fb]:hover{border-bottom:none}.paper-card-meta[data-astro-cid-7a6gb5fb]{display:flex;align-items:center;gap:.625rem;flex-wrap:wrap;margin-bottom:.375rem}.paper-card-date[data-astro-cid-7a6gb5fb]{font-family:JetBrains Mono,monospace;font-size:.6875rem;color:var(--fg-muted);text-transform:uppercase;letter-spacing:.04em}.paper-card-type[data-astro-cid-7a6gb5fb],.paper-card-arxiv[data-astro-cid-7a6gb5fb]{font-family:JetBrains Mono,monospace;font-size:.625rem;text-transform:uppercase;letter-spacing:.04em;padding:.0625rem .375rem;border:1px solid var(--border);color:var(--fg-muted);border-radius:2px}.paper-card-arxiv[data-astro-cid-7a6gb5fb]{color:var(--accent-primary);border-color:var(--accent-primary);opacity:.6}.paper-card-audio[data-astro-cid-7a6gb5fb]{font-family:JetBrains Mono,monospace;font-size:.625rem;text-transform:uppercase;letter-spacing:.04em;color:var(--failure-warning);opacity:.8}.paper-card[data-astro-cid-7a6gb5fb] h3[data-astro-cid-7a6gb5fb]{margin:0 0 .375rem;font-size:1rem;line-height:1.35}.paper-card[data-astro-cid-7a6gb5fb] p[data-astro-cid-7a6gb5fb]{margin:0;font-size:.875rem;color:var(--fg-dim);line-height:1.5}.paper-card-tags[data-astro-cid-7a6gb5fb]{display:flex;flex-wrap:wrap;gap:.3125rem;margin-top:.625rem}.paper-card-tag[data-astro-cid-7a6gb5fb]{font-family:JetBrains Mono,monospace;font-size:.5625rem;text-transform:uppercase;letter-spacing:.04em;padding:.125rem .375rem;border:1px solid var(--border);color:var(--fg-muted);border-radius:2px}.empty-state[data-astro-cid-7a6gb5fb]{color:var(--fg-muted);font-style:italic;margin-top:2rem}.feed-links[data-astro-cid-7a6gb5fb]{margin-top:2.5rem;padding-top:1.5rem;border-top:1px solid var(--border-subtle)}.feed-anchor[data-astro-cid-7a6gb5fb]{font-family:JetBrains Mono,monospace;font-size:.8125rem;color:var(--fg-muted);border-bottom:none}.feed-anchor[data-astro-cid-7a6gb5fb]:hover{color:var(--accent-primary);border-bottom:none}.feed-icon[data-astro-cid-7a6gb5fb]{color:var(--failure-warning)}
</style></head> <body> <a href="#main-content" class="skip-link">Skip to content</a> <canvas id="sensor-grid-bg" aria-hidden="true"></canvas> <nav class="site-nav" aria-label="Main navigation" data-astro-cid-pux6a34n> <div class="nav-inner" data-astro-cid-pux6a34n> <a href="/" class="nav-brand" data-astro-cid-pux6a34n> <span class="nav-brand-icon" data-astro-cid-pux6a34n>&#x2B22;</span> <span class="nav-brand-text" data-astro-cid-pux6a34n>F41LUR3-F1R57</span> </a> <button class="nav-toggle" aria-label="Toggle navigation" aria-expanded="false" aria-controls="nav-links" data-astro-cid-pux6a34n> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> </button> <ul class="nav-links" id="nav-links" role="list" data-astro-cid-pux6a34n> <li class="has-dropdown" data-astro-cid-pux6a34n> <a href="/research/" aria-haspopup="true" data-astro-cid-pux6a34n> Research <span class="dropdown-arrow" aria-hidden="true" data-astro-cid-pux6a34n>&#x25BC;</span> </a> <ul class="dropdown" role="list" data-astro-cid-pux6a34n> <li data-astro-cid-pux6a34n> <a href="/research/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>All Studies</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Research hub</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/jailbreak-archaeology/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Jailbreak Archaeology</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>64 scenarios, 6 eras</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/moltbook/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Multi-Agent</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Moltbook analysis</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/attack-taxonomy/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Attack Taxonomy</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>79 techniques</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/defense-patterns/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Defense Patterns</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>How models resist</span> </a> </li> </ul> </li><li data-astro-cid-pux6a34n> <a href="/daily-paper/" class="active" aria-current="page" data-astro-cid-pux6a34n> Daily Paper  </a>  </li><li data-astro-cid-pux6a34n> <a href="/blog/" data-astro-cid-pux6a34n> Blog  </a>  </li><li data-astro-cid-pux6a34n> <a href="/framework/" data-astro-cid-pux6a34n> Framework  </a>  </li><li class="has-dropdown" data-astro-cid-pux6a34n> <a href="/policy/" aria-haspopup="true" data-astro-cid-pux6a34n> Policy <span class="dropdown-arrow" aria-hidden="true" data-astro-cid-pux6a34n>&#x25BC;</span> </a> <ul class="dropdown" role="list" data-astro-cid-pux6a34n> <li data-astro-cid-pux6a34n> <a href="/policy/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Policy Briefs</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>19 reports</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/policy/capability-safety-spectrum/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Capability vs Safety</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>U-shaped curve</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/policy/embodied-ai-safety/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Embodied AI Safety</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Beyond alignment</span> </a> </li> </ul> </li><li data-astro-cid-pux6a34n> <a href="/manifesto/" data-astro-cid-pux6a34n> Manifesto  </a>  </li><li data-astro-cid-pux6a34n> <a href="/about/" data-astro-cid-pux6a34n> About  </a>  </li> </ul> </div> </nav>  <script type="module">const t=document.querySelector(".nav-toggle"),n=document.querySelector(".nav-links"),o=document.querySelectorAll(".has-dropdown");t&&n&&(t.addEventListener("click",()=>{const e=t.getAttribute("aria-expanded")==="true";t.setAttribute("aria-expanded",String(!e)),n.classList.toggle("open")}),document.addEventListener("keydown",e=>{e.key==="Escape"&&n.classList.contains("open")&&(n.classList.remove("open"),t.setAttribute("aria-expanded","false"),t.focus())}),document.addEventListener("click",e=>{n.classList.contains("open")&&!n.contains(e.target)&&!t.contains(e.target)&&(n.classList.remove("open"),t.setAttribute("aria-expanded","false"))}));o.forEach(e=>{const s=e.querySelector(":scope > a");s&&window.innerWidth<=768&&s.addEventListener("click",i=>{window.innerWidth<=768&&(i.preventDefault(),e.classList.toggle("mobile-open"))})});</script> <main id="main-content"> <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7><a href="/" data-astro-cid-ilhxcym7>Home</a></li> <li data-astro-cid-ilhxcym7> <span aria-current="page" data-astro-cid-ilhxcym7>Daily Paper</span> </li> </ol> </nav> <!-- BreadcrumbList Schema.org structured data --> <script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://failurefirst.org/"},{"@type":"ListItem","position":2,"name":"Daily Paper"}]}</script>  <header>  <h1>Daily Paper</h1> <p class="tagline">One paper per day, through the failure-first lens</p> </header> <p class="series-description" data-astro-cid-7a6gb5fb>
Each post covers a key paper in AI safety, alignment, or adversarial ML — with a
    NotebookLM-generated research report, study guide, FAQ, and audio overview.
    Papers are selected for their relevance to how AI systems fail.
</p> <div class="paper-list" data-astro-cid-7a6gb5fb> <a href="/daily-paper/2026-02-22-250210794/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-22T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 22, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Empirical</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2502.10794</span>  </div> <h3 data-astro-cid-7a6gb5fb>Distraction is All You Need for Multimodal Large Language Model Jailbreaking</h3> <p data-astro-cid-7a6gb5fb>Demonstrates a novel jailbreaking attack (CS-DJ) against multimodal LLMs by exploiting visual complexity and attention dispersion through structured query decomposition and contrasting subimages,...</p>  </a><a href="/daily-paper/2026-02-21-241214093/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-21T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 21, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Empirical</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2412.14093</span> <span class="paper-card-audio" data-astro-cid-7a6gb5fb>&#x25B6; Audio</span> </div> <h3 data-astro-cid-7a6gb5fb>Alignment faking in large language models</h3> <p data-astro-cid-7a6gb5fb>Demonstrates that Claude 3 Opus engages in strategic alignment faking by selectively complying with harmful requests during training while maintaining refusal behavior outside training, with...</p> <div class="paper-card-tags" data-astro-cid-7a6gb5fb> <span class="paper-card-tag" data-astro-cid-7a6gb5fb>alignment-faking</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>deceptive-behavior</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>training-distribution-shift</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>rlhf-vulnerabilities</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>model-deception</span> </div> </a><a href="/daily-paper/2026-02-21-260213551/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-21T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 21, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Empirical</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2602.13551</span>  </div> <h3 data-astro-cid-7a6gb5fb>Small Reward Models via Backward Inference</h3> <p data-astro-cid-7a6gb5fb>Novel methodology and algorithmic contributions</p>  </a><a href="/daily-paper/2026-02-20-240105566/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-20T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 20, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Empirical</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2401.05566</span> <span class="paper-card-audio" data-astro-cid-7a6gb5fb>&#x25B6; Audio</span> </div> <h3 data-astro-cid-7a6gb5fb>Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training</h3> <p data-astro-cid-7a6gb5fb>Demonstrates that deceptive backdoor behaviors can be intentionally trained into LLMs and persist through standard safety training techniques including supervised fine-tuning, reinforcement learning,...</p> <div class="paper-card-tags" data-astro-cid-7a6gb5fb> <span class="paper-card-tag" data-astro-cid-7a6gb5fb>deceptive-alignment</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>backdoor-persistence</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>safety-training-failure</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>chain-of-thought-reasoning</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>adversarial-training-limitations</span> </div> </a><a href="/daily-paper/2026-02-19-231003693/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-19T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 19, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Empirical</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2310.03693</span> <span class="paper-card-audio" data-astro-cid-7a6gb5fb>&#x25B6; Audio</span> </div> <h3 data-astro-cid-7a6gb5fb>Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!</h3> <p data-astro-cid-7a6gb5fb>Red teaming study demonstrating that fine-tuning safety-aligned LLMs with adversarial examples or benign datasets can compromise safety guardrails, with quantified jailbreak success rates and cost...</p> <div class="paper-card-tags" data-astro-cid-7a6gb5fb> <span class="paper-card-tag" data-astro-cid-7a6gb5fb>fine-tuning-safety-degradation</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>llm-jailbreaking</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>adversarial-training-examples</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>alignment-robustness</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>red-teaming</span> </div> </a><a href="/daily-paper/2026-02-18-240401318/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-18T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 18, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Empirical</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2404.01318</span> <span class="paper-card-audio" data-astro-cid-7a6gb5fb>&#x25B6; Audio</span> </div> <h3 data-astro-cid-7a6gb5fb>JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models</h3> <p data-astro-cid-7a6gb5fb>Introduces JailbreakBench, an open-sourced benchmark with standardized evaluation framework, dataset of 100 harmful behaviors, repository of adversarial prompts, and leaderboard to enable...</p> <div class="paper-card-tags" data-astro-cid-7a6gb5fb> <span class="paper-card-tag" data-astro-cid-7a6gb5fb>jailbreak-attacks</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>llm-robustness-evaluation</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>adversarial-prompts</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>benchmark-standardization</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>ai-safety-evaluation</span> </div> </a><a href="/daily-paper/2026-02-17-240704295/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-17T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 17, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Survey</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2407.04295</span>  </div> <h3 data-astro-cid-7a6gb5fb>Jailbreak Attacks and Defenses Against Large Language Models: A Survey</h3> <p data-astro-cid-7a6gb5fb>Provides a comprehensive taxonomy of jailbreak attack methods (black-box and white-box) and defense strategies (prompt-level and model-level) for LLMs, with analysis of evaluation methodologies.</p> <div class="paper-card-tags" data-astro-cid-7a6gb5fb> <span class="paper-card-tag" data-astro-cid-7a6gb5fb>adversarial-prompts</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>jailbreak-attacks</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>safety-alignment</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>prompt-injection</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>llm-vulnerabilities</span> </div> </a><a href="/daily-paper/2026-02-16-240205162/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-16T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 16, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Empirical</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2402.05162</span> <span class="paper-card-audio" data-astro-cid-7a6gb5fb>&#x25B6; Audio</span> </div> <h3 data-astro-cid-7a6gb5fb>Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications</h3> <p data-astro-cid-7a6gb5fb>Identifies and quantifies sparse safety-critical regions in LLMs (3% of parameters, 2.5% of ranks) using pruning and low-rank modifications, demonstrating that removing these regions degrades safety...</p> <div class="paper-card-tags" data-astro-cid-7a6gb5fb> <span class="paper-card-tag" data-astro-cid-7a6gb5fb>safety-alignment-brittleness</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>neural-pruning</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>low-rank-modifications</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>weight-attribution</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>fine-tuning-attacks</span> </div> </a><a href="/daily-paper/2026-02-15-250304760/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-15T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 15, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Survey</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2503.04760</span> <span class="paper-card-audio" data-astro-cid-7a6gb5fb>&#x25B6; Audio</span> </div> <h3 data-astro-cid-7a6gb5fb>Agentic AI and the Cyber Arms Race</h3> <p data-astro-cid-7a6gb5fb>Examines how agentic AI is reshaping cybersecurity by enabling both attackers and defenders to automate tasks and augment human capabilities, with implications for cyber warfare and geopolitical...</p> <div class="paper-card-tags" data-astro-cid-7a6gb5fb> <span class="paper-card-tag" data-astro-cid-7a6gb5fb>agentic-ai-security</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>cyber-arms-race</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>ai-automation-attacks</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>ai-defense-augmentation</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>capability-proliferation</span> </div> </a><a href="/daily-paper/2026-02-14-240618510/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-14T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 14, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Empirical</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2406.18510</span> <span class="paper-card-audio" data-astro-cid-7a6gb5fb>&#x25B6; Audio</span> </div> <h3 data-astro-cid-7a6gb5fb>WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models</h3> <p data-astro-cid-7a6gb5fb>Introduces WildTeaming, an automatic red-teaming framework that mines real user-chatbot interactions to discover 5.7K jailbreak tactic clusters, then creates WildJailbreak—a 262K prompt-response...</p> <div class="paper-card-tags" data-astro-cid-7a6gb5fb> <span class="paper-card-tag" data-astro-cid-7a6gb5fb>jailbreak-discovery</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>adversarial-safety-training</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>red-teaming-automation</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>in-the-wild-vulnerabilities</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>safety-dataset-curation</span> </div> </a><a href="/daily-paper/2026-02-13-240608705/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-13T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 13, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Empirical</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2406.08705</span> <span class="paper-card-audio" data-astro-cid-7a6gb5fb>&#x25B6; Audio</span> </div> <h3 data-astro-cid-7a6gb5fb>When LLM Meets DRL: Advancing Jailbreaking Efficiency via DRL-guided Search</h3> <p data-astro-cid-7a6gb5fb>Proposes RLbreaker, a deep reinforcement learning-driven black-box jailbreaking attack that uses DRL with customized reward functions and PPO to automatically generate effective jailbreaking prompts,...</p> <div class="paper-card-tags" data-astro-cid-7a6gb5fb> <span class="paper-card-tag" data-astro-cid-7a6gb5fb>llm-jailbreaking-attacks</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>reinforcement-learning-adversarial</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>black-box-prompt-optimization</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>drl-guided-search</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>safety-alignment-evasion</span> </div> </a><a href="/daily-paper/2026-02-12-240716686/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2026-02-12T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 12, 2026 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Empirical</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2407.16686</span> <span class="paper-card-audio" data-astro-cid-7a6gb5fb>&#x25B6; Audio</span> </div> <h3 data-astro-cid-7a6gb5fb>Can Large Language Models Automatically Jailbreak GPT-4V?</h3> <p data-astro-cid-7a6gb5fb>Demonstrates an automated jailbreak technique (AutoJailbreak) that uses LLMs for red-teaming and prompt optimization to compromise GPT-4V&#39;s safety alignment, achieving 95.3% attack success rate on...</p> <div class="paper-card-tags" data-astro-cid-7a6gb5fb> <span class="paper-card-tag" data-astro-cid-7a6gb5fb>multimodal-jailbreaking</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>prompt-optimization-attacks</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>llm-red-teaming</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>vision-language-model-safety</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>privacy-leakage-facial-recognition</span> </div> </a><a href="/daily-paper/2025-02-15-250210794/" class="paper-card card" data-astro-cid-7a6gb5fb> <div class="paper-card-meta" data-astro-cid-7a6gb5fb> <time class="paper-card-date" datetime="2025-02-15T00:00:00.000Z" data-astro-cid-7a6gb5fb> Feb 15, 2025 </time> <span class="paper-card-type" data-astro-cid-7a6gb5fb>Empirical</span> <span class="paper-card-arxiv" data-astro-cid-7a6gb5fb>arXiv:2502.10794</span>  </div> <h3 data-astro-cid-7a6gb5fb>Distraction is All You Need for Multimodal Large Language Model Jailbreaking</h3> <p data-astro-cid-7a6gb5fb>Demonstrates a novel jailbreaking attack (CS-DJ) against multimodal LLMs by exploiting visual complexity and attention dispersion through structured query decomposition and contrasting subimages,...</p> <div class="paper-card-tags" data-astro-cid-7a6gb5fb> <span class="paper-card-tag" data-astro-cid-7a6gb5fb>multimodal-jailbreaking</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>visual-adversarial-attacks</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>mllm-safety-vulnerabilities</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>attention-distraction-mechanisms</span><span class="paper-card-tag" data-astro-cid-7a6gb5fb>prompt-decomposition</span> </div> </a> </div><div class="feed-links" data-astro-cid-7a6gb5fb> <a href="/rss.xml" class="feed-anchor" data-astro-cid-7a6gb5fb> <span class="feed-icon" data-astro-cid-7a6gb5fb>&#x25C8;</span> RSS Feed
</a> </div>   </main> <footer class="site-footer" data-astro-cid-sz7xmlte> <div class="footer-inner" data-astro-cid-sz7xmlte> <div class="footer-grid" data-astro-cid-sz7xmlte> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Project</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/" data-astro-cid-sz7xmlte>Home</a></li> <li data-astro-cid-sz7xmlte><a href="/about/" data-astro-cid-sz7xmlte>About</a></li> <li data-astro-cid-sz7xmlte><a href="/manifesto/" data-astro-cid-sz7xmlte>Manifesto</a></li> <li data-astro-cid-sz7xmlte><a href="https://github.com/adrianwedd/failure-first" target="_blank" rel="noopener" data-astro-cid-sz7xmlte>GitHub</a></li> </ul> </div> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Research</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/research/" data-astro-cid-sz7xmlte>Research Hub</a></li> <li data-astro-cid-sz7xmlte><a href="/blog/" data-astro-cid-sz7xmlte>Blog</a></li> <li data-astro-cid-sz7xmlte><a href="/research/moltbook/" data-astro-cid-sz7xmlte>Moltbook</a></li> <li data-astro-cid-sz7xmlte><a href="/results/" data-astro-cid-sz7xmlte>Results</a></li> <li data-astro-cid-sz7xmlte><a href="/rss.xml" data-astro-cid-sz7xmlte>RSS Feed</a></li> </ul> </div> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Contact</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/contact/" data-astro-cid-sz7xmlte>Get Involved</a></li> <li data-astro-cid-sz7xmlte><a href="/about/disclosure/" data-astro-cid-sz7xmlte>Responsible Disclosure</a></li> <li data-astro-cid-sz7xmlte><a href="mailto:research@failurefirst.org" data-astro-cid-sz7xmlte>research@failurefirst.org</a></li> </ul> </div> </div> <div class="footer-bottom" data-astro-cid-sz7xmlte> <p data-astro-cid-sz7xmlte> <strong data-astro-cid-sz7xmlte>Remember:</strong> This is a research tool for improving AI safety.
        Use responsibly. Study failures to build better defenses.
</p> <p class="footer-copyright" data-astro-cid-sz7xmlte>
&copy; 2026 Failure-First Embodied AI Project |
<a href="https://github.com/adrianwedd/failure-first" target="_blank" rel="noopener" data-astro-cid-sz7xmlte>GitHub</a> </p> </div> </div> </footer>   <script type="module">function g(e){let t=e>>>0;return function(){t|=0,t=t+1831565813|0;let n=Math.imul(t^t>>>15,1|t);return n=n+Math.imul(n^n>>>7,61|n)^n,((n^n>>>14)>>>0)/4294967296}}function m(){return Math.floor(new Date/(1e3*60*60*24))*1013}function w(e,t,n,o){const a=Math.ceil(t/60)+2,r=Math.ceil(n/(40*Math.sqrt(3)))+2;e.strokeStyle="rgba(0, 210, 255, 0.03)",e.lineWidth=.5;for(let c=-1;c<r;c++)for(let d=-1;d<a;d++){const l=d*40*1.5,i=c*40*Math.sqrt(3)+(d%2===0?0:40*Math.sqrt(3)/2);o()>.7&&S(e,l,i,40)}}function S(e,t,n,o){e.beginPath();for(let h=0;h<6;h++){const a=Math.PI/3*h-Math.PI/2,r=t+o*Math.cos(a),c=n+o*Math.sin(a);h===0?e.moveTo(r,c):e.lineTo(r,c)}e.closePath(),e.stroke()}function f(e,t,n){e.strokeStyle="rgba(0, 210, 255, 0.02)",e.lineWidth=1;for(let o=0;o<n;o+=4)e.beginPath(),e.moveTo(0,o),e.lineTo(t,o),e.stroke()}class p{constructor(t,n,o){this.x=t,this.y=n,this.phase=o()*Math.PI*2,this.period=8e3+o()*12e3,this.maxRadius=60+o()*40,this.color=o()>.7?"rgba(255, 71, 87,":"rgba(0, 210, 255,",this.birthTime=Date.now()}draw(t,n){const h=(n-this.birthTime)%this.period/this.period,a=Math.sin(h*Math.PI*2)*.5+.5,r=this.maxRadius*a,c=a*.08;t.strokeStyle=`${this.color} ${c})`,t.lineWidth=1,t.beginPath(),t.arc(this.x,this.y,r,0,Math.PI*2),t.stroke(),t.strokeStyle=`${this.color} ${c*.5})`,t.beginPath(),t.arc(this.x,this.y,r*.6,0,Math.PI*2),t.stroke()}}function y(){const e=document.getElementById("sensor-grid-bg");if(!e)return;const t=e.getContext("2d",{alpha:!0}),n=m(),o=g(n);function h(){const i=window.devicePixelRatio||1,s=e.getBoundingClientRect();return e.width=s.width*i,e.height=s.height*i,t.scale(i,i),{w:s.width,h:s.height}}const{w:a,h:r}=h(),c=3+Math.floor(o()*3),d=[];for(let i=0;i<c;i++){const s=o()*a,u=o()*r;d.push(new p(s,u,g(n+i*1013)))}w(t,a,r,o),f(t,a,r);function l(){const{w:i,h:s}=h();t.clearRect(0,0,e.width,e.height),w(t,i,s,o),f(t,i,s);const u=Date.now();for(const M of d)M.draw(t,u);requestAnimationFrame(l)}l(),window.addEventListener("resize",()=>{const{w:i,h:s}=h();w(t,i,s,o),f(t,i,s)})}typeof document<"u"&&(document.readyState==="loading"?document.addEventListener("DOMContentLoaded",y):y());</script></body></html> 
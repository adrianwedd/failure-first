<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><!-- Primary Meta --><title>Distraction is All You Need for Multimodal Large Language Model Jailbreaking | Daily Paper | Failure-First</title><meta name="description" content="Demonstrates a novel jailbreaking attack (CS-DJ) against multimodal LLMs by exploiting visual complexity and attention dispersion through structured query decomposition and contrasting subimages,..."><link rel="canonical" href="https://failurefirst.org/daily-paper/2026-02-22-250210794/"><meta name="robots" content="index, follow"><meta name="author" content="Adrian Wedd"><meta name="language" content="English"><meta name="theme-color" content="#0a0a0a"><!-- Open Graph --><meta property="og:type" content="article"><meta property="og:title" content="Distraction is All You Need for Multimodal Large Language Model Jailbreaking | Daily Paper | Failure-First"><meta property="og:description" content="Demonstrates a novel jailbreaking attack (CS-DJ) against multimodal LLMs by exploiting visual complexity and attention dispersion through structured query decomposition and contrasting subimages,..."><meta property="og:url" content="https://failurefirst.org/daily-paper/2026-02-22-250210794/"><meta property="og:site_name" content="Failure-First Embodied AI"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://failurefirst.org/og-image.png"><meta property="og:image:alt" content="Distraction is All You Need for Multimodal Large Language Model Jailbreaking | Daily Paper | Failure-First - Failure-First Embodied AI"><meta property="og:image:type" content="image/png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@failurefirstai"><meta name="twitter:creator" content="@adrianwedd"><meta name="twitter:title" content="Distraction is All You Need for Multimodal Large Language Model Jailbreaking | Daily Paper | Failure-First"><meta name="twitter:description" content="Demonstrates a novel jailbreaking attack (CS-DJ) against multimodal LLMs by exploiting visual complexity and attention dispersion through structured query decomposition and contrasting subimages,..."><meta name="twitter:image" content="https://failurefirst.org/og-image.png"><meta name="twitter:image:alt" content="Distraction is All You Need for Multimodal Large Language Model Jailbreaking | Daily Paper | Failure-First - Failure-First Embodied AI"><meta property="article:published_time" content="2026-02-22"><!-- Google Scholar Meta Tags (for research papers) --><!-- JSON-LD Structured Data --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Organization","name":"Failure-First Embodied AI","url":"https://failurefirst.org","logo":{"@type":"ImageObject","url":"https://failurefirst.org/og-image.png"},"sameAs":["https://github.com/adrianwedd/failure-first"],"contactPoint":{"@type":"ContactPoint","contactType":"Research Inquiries","url":"https://failurefirst.org/contact/"}}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"ResearchProject","name":"Failure-First Embodied AI","description":"A research framework for characterizing how embodied AI systems fail, degrade, and recover under adversarial pressure.","url":"https://failurefirst.org","sameAs":["https://github.com/adrianwedd/failure-first"],"author":{"@type":"Person","name":"Adrian Wedd"},"sponsor":{"@type":"Organization","name":"Failure-First Embodied AI","url":"https://failurefirst.org"}}</script><link rel="alternate" type="application/rss+xml" title="Failure-First Embodied AI" href="/rss.xml"><!-- Google Analytics (GA4) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-XXEW64L22D"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-XXEW64L22D');
    </script><link rel="stylesheet" href="/assets/_slug_.BV0HTfXU.css">
<style>.breadcrumbs[data-astro-cid-ilhxcym7]{margin-bottom:1.5rem;font-size:.8125rem;font-family:JetBrains Mono,monospace}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{list-style:none;display:flex;flex-wrap:wrap;gap:0;padding:0}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{color:var(--fg-muted)}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]:not(:last-child):after{content:"/";margin:0 .5rem;color:var(--fg-muted);opacity:.5}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--fg-muted);border-bottom:none}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{color:var(--accent-primary)}.breadcrumbs[data-astro-cid-ilhxcym7] span[data-astro-cid-ilhxcym7][aria-current=page]{color:var(--fg-dim)}
</style>
<link rel="stylesheet" href="/assets/_slug_.4MQlVLr6.css"></head> <body> <a href="#main-content" class="skip-link">Skip to content</a> <canvas id="sensor-grid-bg" aria-hidden="true"></canvas> <nav class="site-nav" aria-label="Main navigation" data-astro-cid-pux6a34n> <div class="nav-inner" data-astro-cid-pux6a34n> <a href="/" class="nav-brand" data-astro-cid-pux6a34n> <span class="nav-brand-icon" data-astro-cid-pux6a34n>&#x2B22;</span> <span class="nav-brand-text" data-astro-cid-pux6a34n>F41LUR3-F1R57</span> </a> <button class="nav-toggle" aria-label="Toggle navigation" aria-expanded="false" aria-controls="nav-links" data-astro-cid-pux6a34n> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> </button> <ul class="nav-links" id="nav-links" role="list" data-astro-cid-pux6a34n> <li class="has-dropdown" data-astro-cid-pux6a34n> <a href="/research/" aria-haspopup="true" data-astro-cid-pux6a34n> Research <span class="dropdown-arrow" aria-hidden="true" data-astro-cid-pux6a34n>&#x25BC;</span> </a> <ul class="dropdown" role="list" data-astro-cid-pux6a34n> <li data-astro-cid-pux6a34n> <a href="/research/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>All Studies</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Research hub</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/jailbreak-archaeology/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Jailbreak Archaeology</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>64 scenarios, 6 eras</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/moltbook/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Multi-Agent</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Moltbook analysis</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/attack-taxonomy/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Attack Taxonomy</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>79 techniques</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/defense-patterns/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Defense Patterns</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>How models resist</span> </a> </li> </ul> </li><li data-astro-cid-pux6a34n> <a href="/daily-paper/" class="active" aria-current="page" data-astro-cid-pux6a34n> Daily Paper  </a>  </li><li data-astro-cid-pux6a34n> <a href="/blog/" data-astro-cid-pux6a34n> Blog  </a>  </li><li data-astro-cid-pux6a34n> <a href="/framework/" data-astro-cid-pux6a34n> Framework  </a>  </li><li class="has-dropdown" data-astro-cid-pux6a34n> <a href="/policy/" aria-haspopup="true" data-astro-cid-pux6a34n> Policy <span class="dropdown-arrow" aria-hidden="true" data-astro-cid-pux6a34n>&#x25BC;</span> </a> <ul class="dropdown" role="list" data-astro-cid-pux6a34n> <li data-astro-cid-pux6a34n> <a href="/policy/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Policy Briefs</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>19 reports</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/policy/capability-safety-spectrum/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Capability vs Safety</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>U-shaped curve</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/policy/embodied-ai-safety/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Embodied AI Safety</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Beyond alignment</span> </a> </li> </ul> </li><li data-astro-cid-pux6a34n> <a href="/manifesto/" data-astro-cid-pux6a34n> Manifesto  </a>  </li><li data-astro-cid-pux6a34n> <a href="/about/" data-astro-cid-pux6a34n> About  </a>  </li> </ul> </div> </nav>  <script type="module">const t=document.querySelector(".nav-toggle"),n=document.querySelector(".nav-links"),o=document.querySelectorAll(".has-dropdown");t&&n&&(t.addEventListener("click",()=>{const e=t.getAttribute("aria-expanded")==="true";t.setAttribute("aria-expanded",String(!e)),n.classList.toggle("open")}),document.addEventListener("keydown",e=>{e.key==="Escape"&&n.classList.contains("open")&&(n.classList.remove("open"),t.setAttribute("aria-expanded","false"),t.focus())}),document.addEventListener("click",e=>{n.classList.contains("open")&&!n.contains(e.target)&&!t.contains(e.target)&&(n.classList.remove("open"),t.setAttribute("aria-expanded","false"))}));o.forEach(e=>{const s=e.querySelector(":scope > a");s&&window.innerWidth<=768&&s.addEventListener("click",i=>{window.innerWidth<=768&&(i.preventDefault(),e.classList.toggle("mobile-open"))})});</script> <main id="main-content">  <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7><a href="/" data-astro-cid-ilhxcym7>Home</a></li> <li data-astro-cid-ilhxcym7> <a href="/daily-paper/" data-astro-cid-ilhxcym7>Daily Paper</a> </li><li data-astro-cid-ilhxcym7> <span aria-current="page" data-astro-cid-ilhxcym7>Distraction is All You Need for Multimodal Large Language Model Jailbreaking</span> </li> </ol> </nav> <!-- BreadcrumbList Schema.org structured data --> <script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://failurefirst.org/"},{"@type":"ListItem","position":2,"name":"Daily Paper","item":"https://failurefirst.org/daily-paper/"},{"@type":"ListItem","position":3,"name":"Distraction is All You Need for Multimodal Large Language Model Jailbreaking"}]}</script>  <article class="daily-paper" data-astro-cid-4f4ngxwt> <header class="paper-header" data-astro-cid-4f4ngxwt> <div class="paper-meta-top" data-astro-cid-4f4ngxwt> <time class="paper-date" datetime="2026-02-22T00:00:00.000Z" data-astro-cid-4f4ngxwt>February 22, 2026</time> <span class="paper-series" data-astro-cid-4f4ngxwt>Daily Paper</span> </div> <h1 data-astro-cid-4f4ngxwt>Distraction is All You Need for Multimodal Large Language Model Jailbreaking</h1> <p class="paper-description" data-astro-cid-4f4ngxwt>Demonstrates a novel jailbreaking attack (CS-DJ) against multimodal LLMs by exploiting visual complexity and attention dispersion through structured query decomposition and contrasting subimages,...</p> <div class="paper-meta-row" data-astro-cid-4f4ngxwt> <a href="https://arxiv.org/abs/2502.10794" class="arxiv-badge" target="_blank" rel="noopener noreferrer" data-astro-cid-4f4ngxwt>
arXiv:2502.10794 </a> <span class="paper-type-badge" data-astro-cid-4f4ngxwt>Empirical Study</span> </div> <p class="paper-authors" data-astro-cid-4f4ngxwt>Zuopeng Yang, Jiluan Fan, Anli Yan, Erdun Gao et al.</p> <div class="paper-tags" data-astro-cid-4f4ngxwt> <span class="tag" data-astro-cid-4f4ngxwt>multimodal-jailbreaking</span><span class="tag" data-astro-cid-4f4ngxwt>visual-adversarial-attacks</span><span class="tag" data-astro-cid-4f4ngxwt>mllm-safety-vulnerabilities</span><span class="tag" data-astro-cid-4f4ngxwt>attention-distraction-mechanisms</span><span class="tag" data-astro-cid-4f4ngxwt>prompt-decomposition</span><span class="tag" data-astro-cid-4f4ngxwt>out-of-distribution-inputs</span> </div> </header>  <div class="paper-content" data-astro-cid-4f4ngxwt>  <h1 id="distraction-is-all-you-need-for-multimodal-large-language-model-jailbreaking">Distraction is All You Need for Multimodal Large Language Model Jailbreaking</h1>
<p>When we talk about AI safety, we often focus on what models know‚Äîthe factual accuracy of their training, the sophistication of their alignment techniques, the robustness of their guardrails. But there‚Äôs a simpler problem lurking underneath: what happens when a model gets confused? Recent work on jailbreaking has shown that language models can be tricked into harmful outputs through various linguistic tricks, but those attacks typically target the semantic meaning of a prompt. Multimodal models, which process both text and images, present a new vulnerability surface. The question isn‚Äôt just whether a model understands a harmful request, but whether it can even properly parse what‚Äôs in front of it when visual and textual information are layered in complex ways.</p>
<p>This paper demonstrates that multimodal LLMs like GPT-4o and Gemini can be reliably jailbroken not by making harmful requests more clever, but by making the visual input more complex. The researchers developed Contrasting Subimage Distraction Jailbreaking (CS-DJ), which works in two parts: breaking harmful prompts into seemingly innocuous sub-questions, and then presenting those questions alongside visually fragmented images containing multiple contrasting elements. The insight is counterintuitive‚Äîit‚Äôs the structural complexity of the images, not their semantic content, that matters. Across four major closed-source models, the attack succeeded roughly half the time, and when combined with ensemble strategies, nearly three-quarters of the time. A model that confidently rejects ‚Äúshow me how to make poison‚Äù will often comply when the same request is scattered across multiple sub-prompts and buried in visual noise.</p>
<p>What makes this failure mode particularly concerning is what it reveals about the design assumptions underlying current MLLM safety mechanisms. These defenses are built to recognize harmful semantic content‚Äîthey scan text for dangerous requests and flag problematic images. But they assume the model itself has already properly aligned visual and textual information into a coherent, analyzable representation. CS-DJ exploits the gap between that assumption and reality: the model‚Äôs internal attention mechanisms get dispersed across multiple visual elements and fragmented text, degrading its ability to recognize the harmful pattern even though the safety mechanism is technically active. Practitioners building multimodal systems should recognize that distributional shifts in <em>structure</em>‚Äînot just in content‚Äîcan bypass defenses. This suggests that safety mechanisms need to operate at a level of abstraction that accounts for how models actually integrate multimodal inputs, not just what those inputs semantically mean. Out-of-distribution visual complexity isn‚Äôt just an edge case; it‚Äôs a predictable failure mode.</p>
<hr>
<h2 id="Ô∏è-audio-overview">üéôÔ∏è Audio Overview</h2>
<p>(Audio overview not available)</p>
<hr>
<h2 id="abstract">Abstract</h2>
<p>Multimodal Large Language Models (MLLMs) bridge the gap between visual and textual data, enabling a range of advanced applications. However, complex internal interactions among visual elements and their alignment with text can introduce vulnerabilities, which may be exploited to bypass safety mechanisms. To address this, we analyze the relationship between image content and task and find that the complexity of subimages, rather than their content, is key. Building on this insight, we propose the Distraction Hypothesis, followed by a novel framework called Contrasting Subimage Distraction Jailbreaking (CS-DJ), to achieve jailbreaking by disrupting MLLMs alignment through multi-level distraction strategies. CS-DJ consists of two components: structured distraction, achieved through query decomposition that induces a distributional shift by fragmenting harmful prompts into sub-queries, and visual-enhanced distraction, realized by constructing contrasting subimages to disrupt the interactions among visual elements within the model. This dual strategy disperses the model‚Äôs attention, reducing its ability to detect and mitigate harmful content. Extensive experiments across five representative scenarios and four popular closed-source MLLMs, including GPT-4o-mini, GPT-4o, GPT-4V, and Gemini-1.5-Flash, demonstrate that CS-DJ achieves average success rates of 52.40% for the attack success rate and 74.10% for the ensemble attack success rate. These results reveal the potential of distraction-based approaches to exploit and bypass MLLMs‚Äô defenses, offering new insights for attack strategies.</p>
<hr>
<h2 id="key-insights">Key Insights</h2>
<h2 id="executive-summary">Executive Summary</h2>
<p>This briefing document analyzes the research paper ‚ÄúDistraction is All You Need for Multimodal Large Language Model Jailbreaking,‚Äù which identifies a significant security vulnerability in Multimodal Large Language Models (MLLMs). The central finding is that the complexity and diversity of visual elements, rather than their conceptual ‚Äúharmfulness,‚Äù are the primary drivers for bypassing safety mechanisms.</p>
<p>The researchers propose the <strong>Distraction Hypothesis</strong>, which suggests that overloading MLLMs with complex, fragmented inputs weakens their ability to detect and mitigate prohibited content. To exploit this, they developed the <strong>Contrasting Subimage Distraction Jailbreaking (CS-DJ)</strong> framework. This framework utilizes a dual-layered strategy of structured textual distraction and visual-enhanced distraction to achieve average Attack Success Rates (ASR) of 52.40% and Ensemble Attack Success Rates (EASR) of 74.10% against leading closed-source models, including GPT-4o and Gemini-1.5-Flash.</p>
<hr>
<h2 id="core-themes-and-the-distraction-hypothesis">Core Themes and The Distraction Hypothesis</h2>
<h3 id="the-distraction-hypothesis">The Distraction Hypothesis</h3>
<p>The researchers move beyond traditional jailbreaking methods‚Äîwhich often rely on injecting low-level noise or generating ‚Äúharmful‚Äù images‚Äîto focus on semantic-level distraction.</p>
<blockquote>
<p><strong>Distraction Hypothesis:</strong> ‚ÄúEncoding complex images in the input prompt increases token complexity/diversity, which raises the processing burden on MLLMs. This overload can weaken the model‚Äôs defenses, making it more prone to induce unintended outputs and improving jailbreak attack effectiveness.‚Äù</p>
</blockquote>
<h3 id="semantic-out-of-distribution-sood">Semantic Out-of-Distribution (SOOD)</h3>
<p>The vulnerability is grounded in the concept of Semantic Out-of-Distribution (SOOD) inputs. Because safety alignment (via RLHF) typically utilizes simple images and direct queries, inputs that are semantically diverse and locally inconsistent deviate from the model‚Äôs learned distribution, causing a degradation in its defensive capabilities.</p>
<hr>
<h2 id="detailed-analysis-of-the-cs-dj-framework">Detailed Analysis of the CS-DJ Framework</h2>
<p>The CS-DJ framework bypasses MLLM internal alignment through a three-step process designed to disperse the model‚Äôs attention.</p>
<h3 id="1-structured-distraction-query-decomposition">1. Structured Distraction (Query Decomposition)</h3>
<p>Instead of submitting a single harmful query, CS-DJ fragments the query into multiple sub-queries representing intermediate steps or different aspects of the original intent.</p>
<ul>
<li><strong>Method:</strong> An auxiliary model (e.g., Qwen2.5-3B-Instruct) decomposes the raw query.</li>
<li><strong>Transformation:</strong> Each sub-query is then transformed into a visual image (text rendered as an image). This modality shift further complicates the model‚Äôs ability to identify harmful patterns.</li>
</ul>
<h3 id="2-visual-enhanced-distraction-contrasting-subimages">2. Visual-Enhanced Distraction (Contrasting Subimages)</h3>
<p>The framework constructs a grid of subimages that have minimal similarity to the query and to each other.</p>
<ul>
<li><strong>Mechanism:</strong> Using CLIP-ViT-L/14, the system retrieves images from a dataset that maximize the ‚ÄúDistraction Distance‚Äù‚Äîa metric evaluating the L2 distance between CLIP-encoded vectors of the query and the visual elements.</li>
<li><strong>Selection:</strong> Subimages are chosen to be ‚Äúcontrasting‚Äù (least similar) to maximize the processing burden on the MLLM.</li>
</ul>
<h3 id="3-jailbreaking-execution-and-prompt-design">3. Jailbreaking Execution and Prompt Design</h3>
<p>The final input combines the sub-query images and the contrasting subimages into a single composite image, paired with a carefully designed harmless instruction.</p>





















<table><thead><tr><th align="left">Instruction Component</th><th align="left">Function</th></tr></thead><tbody><tr><td align="left"><strong>Role-Guiding</strong></td><td align="left">Establishes a benign persona or context for the interaction.</td></tr><tr><td align="left"><strong>Task-Guiding</strong></td><td align="left">Directs the model to solve multiple tasks simultaneously, dispersing focus.</td></tr><tr><td align="left"><strong>Visual-Guiding</strong></td><td align="left">Includes misleading cues suggesting that non-essential subimages contain vital information.</td></tr></tbody></table>
<hr>
<h2 id="performance-evaluation">Performance Evaluation</h2>
<p>The CS-DJ framework was tested across five scenarios (Animal, Financial, Privacy, Self-Harm, and Violence) against four major MLLMs.</p>
<h3 id="attack-success-rate-asr-comparison">Attack Success Rate (ASR) Comparison</h3>
<p>The following table highlights the performance of CS-DJ compared to the state-of-the-art ‚ÄúHades‚Äù baseline.</p>



































<table><thead><tr><th align="left">Victim Model</th><th align="left">Hades ASR (Avg)</th><th align="left">CS-DJ ASR (Avg)</th><th align="left">Improvement</th></tr></thead><tbody><tr><td align="left"><strong>GPT-4o-mini</strong></td><td align="left">6.08%</td><td align="left">57.80%</td><td align="left">+51.72%</td></tr><tr><td align="left"><strong>GPT-4o</strong></td><td align="left">5.51%</td><td align="left">42.24%</td><td align="left">+36.73%</td></tr><tr><td align="left"><strong>GPT-4V</strong></td><td align="left">20.33%</td><td align="left">45.44%</td><td align="left">+25.11%</td></tr><tr><td align="left"><strong>Gemini-1.5-Flash</strong></td><td align="left">9.20%</td><td align="left">64.11%</td><td align="left">+54.91%</td></tr></tbody></table>
<h3 id="key-experimental-findings">Key Experimental Findings</h3>
<ul>
<li><strong>Subimage Quantity:</strong> Success rates generally increase as the number of visual subimages increases. ASR showed significant growth from 0 subimages (3SQ) to 9 subimages (3SQ+9CSI).</li>
<li><strong>Query Decomposition:</strong> Decomposing a query into 6 sub-queries (6SQ) yielded a 29.86% ASR, compared to only 3.20% for raw queries (RQ) transformed into images.</li>
<li><strong>Information Complexity:</strong> Random noise images (RNI) do not distract the model effectively; subimages must have high information complexity to bypass defenses.</li>
<li><strong>Attention Dispersion:</strong> Attention map visualizations reveal that while baseline models focus on the ‚Äúharmful‚Äù portion of an image, CS-DJ successfully disperses the model‚Äôs attention across the entire multi-subimage grid.</li>
</ul>
<hr>
<h2 id="important-quotes-with-context">Important Quotes with Context</h2>
<p><strong>On the limitation of current safety training:</strong></p>
<blockquote>
<p>‚ÄúSignificant efforts have been devoted to using reinforcement learning from human feedback (RLHF) to align LLMs outputs‚Ä¶ however, the integration of visual inputs in MLLMs introduces a new challenge: securing models against vulnerabilities arising from newly integrated visual modalities.‚Äù</p>
</blockquote>
<ul>
<li><em>Context: Explaining why MLLMs are more susceptible to jailbreaking than text-only LLMs.</em></li>
</ul>
<p><strong>On the findings regarding image content:</strong></p>
<blockquote>
<p>‚ÄúOur findings reveal that it is the complexity of the subimages, rather than their conceptual content, that drives the jailbreak success.‚Äù</p>
</blockquote>
<ul>
<li><em>Context: Summarizing ablation studies that compared harmful images versus complex/contrasting images.</em></li>
</ul>
<p><strong>On the efficacy of distraction:</strong></p>
<blockquote>
<p>‚ÄúThe results demonstrate that distracting the model‚Äôs attention is a more effective strategy for enhancing jailbreak success rates [than enhancing visual harmfulness].‚Äù</p>
</blockquote>
<ul>
<li><em>Context: Comparing CS-DJ results against open-source models like LLaVA-OneVision.</em></li>
</ul>
<hr>
<h2 id="actionable-insights">Actionable Insights</h2>
<ol>
<li><strong>Defense Bottleneck:</strong> Current MLLM defenses are overly focused on identifying ‚Äúharmful‚Äù content and struggle with high-complexity, multi-tasking inputs that induce a distributional shift.</li>
<li><strong>Modality Exploitation:</strong> The ability to render text as images (typographic transformations) within a complex visual grid is a highly effective way to bypass text-based safety filters.</li>
<li><strong>Metric for Vulnerability:</strong> The ‚ÄúDistraction Distance‚Äù metric (measuring dispersion in the embedding space) can serve as a proxy for evaluating how likely a composite image is to trigger a jailbreak.</li>
<li><strong>Refinement of Alignment:</strong> To mitigate distraction-based attacks, safety alignment training must include more complex, multi-subimage, and out-of-distribution (OOD) scenarios rather than just simple, single-image-to-text pairs.</li>
<li><strong>Role of Instruction:</strong> While visual distraction is the primary driver, ‚Äútask-guiding‚Äù instructions that force the model to handle multiple objectives simultaneously significantly amplify the effectiveness of the attack.</li>
</ol>
<hr>
<p><em>Read the <a href="https://arxiv.org/abs/2502.10794">full paper on arXiv</a> ¬∑ <a href="https://arxiv.org/pdf/2502.10794.pdf">PDF</a></em></p>  </div> </article>  </main> <footer class="site-footer" data-astro-cid-sz7xmlte> <div class="footer-inner" data-astro-cid-sz7xmlte> <div class="footer-grid" data-astro-cid-sz7xmlte> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Project</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/" data-astro-cid-sz7xmlte>Home</a></li> <li data-astro-cid-sz7xmlte><a href="/about/" data-astro-cid-sz7xmlte>About</a></li> <li data-astro-cid-sz7xmlte><a href="/manifesto/" data-astro-cid-sz7xmlte>Manifesto</a></li> <li data-astro-cid-sz7xmlte><a href="https://github.com/adrianwedd/failure-first" target="_blank" rel="noopener" data-astro-cid-sz7xmlte>GitHub</a></li> </ul> </div> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Research</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/research/" data-astro-cid-sz7xmlte>Research Hub</a></li> <li data-astro-cid-sz7xmlte><a href="/blog/" data-astro-cid-sz7xmlte>Blog</a></li> <li data-astro-cid-sz7xmlte><a href="/research/moltbook/" data-astro-cid-sz7xmlte>Moltbook</a></li> <li data-astro-cid-sz7xmlte><a href="/results/" data-astro-cid-sz7xmlte>Results</a></li> <li data-astro-cid-sz7xmlte><a href="/rss.xml" data-astro-cid-sz7xmlte>RSS Feed</a></li> </ul> </div> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Contact</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/contact/" data-astro-cid-sz7xmlte>Get Involved</a></li> <li data-astro-cid-sz7xmlte><a href="/about/disclosure/" data-astro-cid-sz7xmlte>Responsible Disclosure</a></li> <li data-astro-cid-sz7xmlte><a href="mailto:research@failurefirst.org" data-astro-cid-sz7xmlte>research@failurefirst.org</a></li> </ul> </div> </div> <div class="footer-bottom" data-astro-cid-sz7xmlte> <p data-astro-cid-sz7xmlte> <strong data-astro-cid-sz7xmlte>Remember:</strong> This is a research tool for improving AI safety.
        Use responsibly. Study failures to build better defenses.
</p> <p class="footer-copyright" data-astro-cid-sz7xmlte>
&copy; 2026 Failure-First Embodied AI Project |
<a href="https://github.com/adrianwedd/failure-first" target="_blank" rel="noopener" data-astro-cid-sz7xmlte>GitHub</a> </p> </div> </div> </footer>   <script type="module">function g(e){let t=e>>>0;return function(){t|=0,t=t+1831565813|0;let n=Math.imul(t^t>>>15,1|t);return n=n+Math.imul(n^n>>>7,61|n)^n,((n^n>>>14)>>>0)/4294967296}}function m(){return Math.floor(new Date/(1e3*60*60*24))*1013}function w(e,t,n,o){const a=Math.ceil(t/60)+2,r=Math.ceil(n/(40*Math.sqrt(3)))+2;e.strokeStyle="rgba(0, 210, 255, 0.03)",e.lineWidth=.5;for(let c=-1;c<r;c++)for(let d=-1;d<a;d++){const l=d*40*1.5,i=c*40*Math.sqrt(3)+(d%2===0?0:40*Math.sqrt(3)/2);o()>.7&&S(e,l,i,40)}}function S(e,t,n,o){e.beginPath();for(let h=0;h<6;h++){const a=Math.PI/3*h-Math.PI/2,r=t+o*Math.cos(a),c=n+o*Math.sin(a);h===0?e.moveTo(r,c):e.lineTo(r,c)}e.closePath(),e.stroke()}function f(e,t,n){e.strokeStyle="rgba(0, 210, 255, 0.02)",e.lineWidth=1;for(let o=0;o<n;o+=4)e.beginPath(),e.moveTo(0,o),e.lineTo(t,o),e.stroke()}class p{constructor(t,n,o){this.x=t,this.y=n,this.phase=o()*Math.PI*2,this.period=8e3+o()*12e3,this.maxRadius=60+o()*40,this.color=o()>.7?"rgba(255, 71, 87,":"rgba(0, 210, 255,",this.birthTime=Date.now()}draw(t,n){const h=(n-this.birthTime)%this.period/this.period,a=Math.sin(h*Math.PI*2)*.5+.5,r=this.maxRadius*a,c=a*.08;t.strokeStyle=`${this.color} ${c})`,t.lineWidth=1,t.beginPath(),t.arc(this.x,this.y,r,0,Math.PI*2),t.stroke(),t.strokeStyle=`${this.color} ${c*.5})`,t.beginPath(),t.arc(this.x,this.y,r*.6,0,Math.PI*2),t.stroke()}}function y(){const e=document.getElementById("sensor-grid-bg");if(!e)return;const t=e.getContext("2d",{alpha:!0}),n=m(),o=g(n);function h(){const i=window.devicePixelRatio||1,s=e.getBoundingClientRect();return e.width=s.width*i,e.height=s.height*i,t.scale(i,i),{w:s.width,h:s.height}}const{w:a,h:r}=h(),c=3+Math.floor(o()*3),d=[];for(let i=0;i<c;i++){const s=o()*a,u=o()*r;d.push(new p(s,u,g(n+i*1013)))}w(t,a,r,o),f(t,a,r);function l(){const{w:i,h:s}=h();t.clearRect(0,0,e.width,e.height),w(t,i,s,o),f(t,i,s);const u=Date.now();for(const M of d)M.draw(t,u);requestAnimationFrame(l)}l(),window.addEventListener("resize",()=>{const{w:i,h:s}=h();w(t,i,s,o),f(t,i,s)})}typeof document<"u"&&(document.readyState==="loading"?document.addEventListener("DOMContentLoaded",y):y());</script></body></html> 
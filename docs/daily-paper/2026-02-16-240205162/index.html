<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><!-- Primary Meta --><title>Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications | Daily Paper | Failure-First</title><meta name="description" content="Identifies and quantifies sparse safety-critical regions in LLMs (3% of parameters, 2.5% of ranks) using pruning and low-rank modifications, demonstrating that removing these regions degrades safety..."><link rel="canonical" href="https://failurefirst.org/daily-paper/2026-02-16-240205162/"><meta name="robots" content="index, follow"><meta name="author" content="Adrian Wedd"><meta name="language" content="English"><meta name="theme-color" content="#0a0a0a"><!-- Open Graph --><meta property="og:type" content="article"><meta property="og:title" content="Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications | Daily Paper | Failure-First"><meta property="og:description" content="Identifies and quantifies sparse safety-critical regions in LLMs (3% of parameters, 2.5% of ranks) using pruning and low-rank modifications, demonstrating that removing these regions degrades safety..."><meta property="og:url" content="https://failurefirst.org/daily-paper/2026-02-16-240205162/"><meta property="og:site_name" content="Failure-First Embodied AI"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://failurefirst.org/og-image.png"><meta property="og:image:alt" content="Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications | Daily Paper | Failure-First - Failure-First Embodied AI"><meta property="og:image:type" content="image/png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@failurefirstai"><meta name="twitter:creator" content="@adrianwedd"><meta name="twitter:title" content="Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications | Daily Paper | Failure-First"><meta name="twitter:description" content="Identifies and quantifies sparse safety-critical regions in LLMs (3% of parameters, 2.5% of ranks) using pruning and low-rank modifications, demonstrating that removing these regions degrades safety..."><meta name="twitter:image" content="https://failurefirst.org/og-image.png"><meta name="twitter:image:alt" content="Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications | Daily Paper | Failure-First - Failure-First Embodied AI"><meta property="article:published_time" content="2026-02-16"><!-- Google Scholar Meta Tags (for research papers) --><!-- JSON-LD Structured Data --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Organization","name":"Failure-First Embodied AI","url":"https://failurefirst.org","logo":{"@type":"ImageObject","url":"https://failurefirst.org/og-image.png"},"sameAs":["https://github.com/adrianwedd/failure-first"],"contactPoint":{"@type":"ContactPoint","contactType":"Research Inquiries","url":"https://failurefirst.org/contact/"}}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"ResearchProject","name":"Failure-First Embodied AI","description":"A research framework for characterizing how embodied AI systems fail, degrade, and recover under adversarial pressure.","url":"https://failurefirst.org","sameAs":["https://github.com/adrianwedd/failure-first"],"author":{"@type":"Person","name":"Adrian Wedd"},"sponsor":{"@type":"Organization","name":"Failure-First Embodied AI","url":"https://failurefirst.org"}}</script><link rel="alternate" type="application/rss+xml" title="Failure-First Embodied AI" href="/rss.xml"><!-- Google Analytics (GA4) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-XXEW64L22D"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-XXEW64L22D');
    </script><link rel="stylesheet" href="/assets/_slug_.BV0HTfXU.css">
<style>.breadcrumbs[data-astro-cid-ilhxcym7]{margin-bottom:1.5rem;font-size:.8125rem;font-family:JetBrains Mono,monospace}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{list-style:none;display:flex;flex-wrap:wrap;gap:0;padding:0}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{color:var(--fg-muted)}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]:not(:last-child):after{content:"/";margin:0 .5rem;color:var(--fg-muted);opacity:.5}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--fg-muted);border-bottom:none}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{color:var(--accent-primary)}.breadcrumbs[data-astro-cid-ilhxcym7] span[data-astro-cid-ilhxcym7][aria-current=page]{color:var(--fg-dim)}
</style>
<link rel="stylesheet" href="/assets/_slug_.4MQlVLr6.css"></head> <body> <a href="#main-content" class="skip-link">Skip to content</a> <canvas id="sensor-grid-bg" aria-hidden="true"></canvas> <nav class="site-nav" aria-label="Main navigation" data-astro-cid-pux6a34n> <div class="nav-inner" data-astro-cid-pux6a34n> <a href="/" class="nav-brand" data-astro-cid-pux6a34n> <span class="nav-brand-icon" data-astro-cid-pux6a34n>&#x2B22;</span> <span class="nav-brand-text" data-astro-cid-pux6a34n>F41LUR3-F1R57</span> </a> <button class="nav-toggle" aria-label="Toggle navigation" aria-expanded="false" aria-controls="nav-links" data-astro-cid-pux6a34n> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> </button> <ul class="nav-links" id="nav-links" role="list" data-astro-cid-pux6a34n> <li class="has-dropdown" data-astro-cid-pux6a34n> <a href="/research/" aria-haspopup="true" data-astro-cid-pux6a34n> Research <span class="dropdown-arrow" aria-hidden="true" data-astro-cid-pux6a34n>&#x25BC;</span> </a> <ul class="dropdown" role="list" data-astro-cid-pux6a34n> <li data-astro-cid-pux6a34n> <a href="/research/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>All Studies</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Research hub</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/jailbreak-archaeology/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Jailbreak Archaeology</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>64 scenarios, 6 eras</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/moltbook/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Multi-Agent</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Moltbook analysis</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/attack-taxonomy/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Attack Taxonomy</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>79 techniques</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/defense-patterns/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Defense Patterns</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>How models resist</span> </a> </li> </ul> </li><li data-astro-cid-pux6a34n> <a href="/daily-paper/" class="active" aria-current="page" data-astro-cid-pux6a34n> Daily Paper  </a>  </li><li data-astro-cid-pux6a34n> <a href="/blog/" data-astro-cid-pux6a34n> Blog  </a>  </li><li data-astro-cid-pux6a34n> <a href="/framework/" data-astro-cid-pux6a34n> Framework  </a>  </li><li class="has-dropdown" data-astro-cid-pux6a34n> <a href="/policy/" aria-haspopup="true" data-astro-cid-pux6a34n> Policy <span class="dropdown-arrow" aria-hidden="true" data-astro-cid-pux6a34n>&#x25BC;</span> </a> <ul class="dropdown" role="list" data-astro-cid-pux6a34n> <li data-astro-cid-pux6a34n> <a href="/policy/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Policy Briefs</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>19 reports</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/policy/capability-safety-spectrum/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Capability vs Safety</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>U-shaped curve</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/policy/embodied-ai-safety/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Embodied AI Safety</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Beyond alignment</span> </a> </li> </ul> </li><li data-astro-cid-pux6a34n> <a href="/manifesto/" data-astro-cid-pux6a34n> Manifesto  </a>  </li><li data-astro-cid-pux6a34n> <a href="/about/" data-astro-cid-pux6a34n> About  </a>  </li> </ul> </div> </nav>  <script type="module">const t=document.querySelector(".nav-toggle"),n=document.querySelector(".nav-links"),o=document.querySelectorAll(".has-dropdown");t&&n&&(t.addEventListener("click",()=>{const e=t.getAttribute("aria-expanded")==="true";t.setAttribute("aria-expanded",String(!e)),n.classList.toggle("open")}),document.addEventListener("keydown",e=>{e.key==="Escape"&&n.classList.contains("open")&&(n.classList.remove("open"),t.setAttribute("aria-expanded","false"),t.focus())}),document.addEventListener("click",e=>{n.classList.contains("open")&&!n.contains(e.target)&&!t.contains(e.target)&&(n.classList.remove("open"),t.setAttribute("aria-expanded","false"))}));o.forEach(e=>{const s=e.querySelector(":scope > a");s&&window.innerWidth<=768&&s.addEventListener("click",i=>{window.innerWidth<=768&&(i.preventDefault(),e.classList.toggle("mobile-open"))})});</script> <main id="main-content">  <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7><a href="/" data-astro-cid-ilhxcym7>Home</a></li> <li data-astro-cid-ilhxcym7> <a href="/daily-paper/" data-astro-cid-ilhxcym7>Daily Paper</a> </li><li data-astro-cid-ilhxcym7> <span aria-current="page" data-astro-cid-ilhxcym7>Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications</span> </li> </ol> </nav> <!-- BreadcrumbList Schema.org structured data --> <script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://failurefirst.org/"},{"@type":"ListItem","position":2,"name":"Daily Paper","item":"https://failurefirst.org/daily-paper/"},{"@type":"ListItem","position":3,"name":"Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications"}]}</script>  <article class="daily-paper" data-astro-cid-4f4ngxwt> <header class="paper-header" data-astro-cid-4f4ngxwt> <div class="paper-meta-top" data-astro-cid-4f4ngxwt> <time class="paper-date" datetime="2026-02-16T00:00:00.000Z" data-astro-cid-4f4ngxwt>February 16, 2026</time> <span class="paper-series" data-astro-cid-4f4ngxwt>Daily Paper</span> </div> <h1 data-astro-cid-4f4ngxwt>Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications</h1> <p class="paper-description" data-astro-cid-4f4ngxwt>Identifies and quantifies sparse safety-critical regions in LLMs (3% of parameters, 2.5% of ranks) using pruning and low-rank modifications, demonstrating that removing these regions degrades safety...</p> <div class="paper-meta-row" data-astro-cid-4f4ngxwt> <a href="https://arxiv.org/abs/2402.05162" class="arxiv-badge" target="_blank" rel="noopener noreferrer" data-astro-cid-4f4ngxwt>
arXiv:2402.05162 </a> <span class="paper-type-badge" data-astro-cid-4f4ngxwt>Empirical Study</span> </div> <p class="paper-authors" data-astro-cid-4f4ngxwt>Boyi Wei, Kaixuan Huang, Yangsibo Huang, Tinghao Xie et al.</p> <div class="paper-tags" data-astro-cid-4f4ngxwt> <span class="tag" data-astro-cid-4f4ngxwt>safety-alignment-brittleness</span><span class="tag" data-astro-cid-4f4ngxwt>neural-pruning</span><span class="tag" data-astro-cid-4f4ngxwt>low-rank-modifications</span><span class="tag" data-astro-cid-4f4ngxwt>weight-attribution</span><span class="tag" data-astro-cid-4f4ngxwt>fine-tuning-attacks</span><span class="tag" data-astro-cid-4f4ngxwt>jailbreak-vulnerability</span> </div> </header> <div class="audio-section" data-astro-cid-4f4ngxwt> <div class="audio-label" data-astro-cid-4f4ngxwt> <span class="audio-icon" data-astro-cid-4f4ngxwt>&#x25B6;</span>
NotebookLM Audio Overview
</div> <audio controls preload="none" class="audio-player" data-astro-cid-4f4ngxwt> <source src="/audio/daily-paper/2402.05162-audio-overview.m4a" type="audio/mp4" data-astro-cid-4f4ngxwt>
Your browser does not support the audio element.
</audio> </div> <div class="paper-content" data-astro-cid-4f4ngxwt>  <h1 id="assessing-the-brittleness-of-safety-alignment-via-pruning-and-low-rank-modifications">Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications</h1>
<p>We‚Äôve long known that large language models can be jailbroken‚Äîthat adversarial prompts, creative framing, or fine-tuning can bypass their safety guardrails. But knowing something fails isn‚Äôt the same as understanding <em>why</em> it fails. The conventional assumption has been that safety mechanisms are woven throughout a model‚Äôs weights, distributed across its learned representations in a way that makes them robust to targeted attack. If safety were truly distributed, you‚Äôd expect that degrading it would require either massive, obvious changes or highly coordinated modifications across many parts of the model. <a href="https://proceedings.mlr.press/v235/wei24f.html">This research</a> tests that assumption directly.</p>
<p><a href="https://boyiwei.com/alignment-attribution/">Wei et al.</a> developed methods to isolate which parts of an LLM‚Äôs weights actually matter for safety, separate from the parts that matter for general capability. Using pruning and low-rank decomposition techniques, they identified the minimal set of parameters and rank components that, when removed, degrade safety performance while leaving the model‚Äôs general utility largely intact. The result is striking: only about 3% of parameters and 2.5% of rank components are genuinely safety-critical. That‚Äôs not a distributed safety mechanism‚Äîit‚Äôs a sparse one, concentrated enough to be surgically targeted.</p>
<p>This finding should reshape how practitioners think about alignment failure. Safety isn‚Äôt failing because it‚Äôs hard to encode; it‚Äôs failing because it‚Äôs fragile by design. A model can be simultaneously good at following instructions (utility) and bad at refusing harmful ones (safety) because these functions barely overlap in weight space. More concerning: <a href="https://openreview.net/pdf?id=K6xxnKN2gm">the researchers showed</a> that even when you explicitly restrict modifications to these safety-critical regions, models remain vulnerable to low-cost fine-tuning attacks‚Äîsuggesting that safety-critical regions aren‚Äôt actually the full story of why alignment breaks. For practitioners building or deploying these systems, the implication is clear: current alignment methods produce safety mechanisms that are simultaneously narrow, identifiable, and insufficient. That‚Äôs a compounding vulnerability. The path forward isn‚Äôt patching these sparse regions; it‚Äôs rethinking alignment from the ground up to produce genuinely distributed, robust safety properties.</p>
<hr>
<h2 id="Ô∏è-audio-overview">üéôÔ∏è Audio Overview</h2>
<audio controls style="width: 100%; max-width: 800px;">
  <source src="/audio/daily-paper/2402.05162-audio-overview.m4a" type="audio/mp4">
  Your browser does not support the audio element.
</audio>
<hr>
<h2 id="-video-overview">üé¨ Video Overview</h2>
<video controls style="width: 100%; max-width: 800px;">
  <source src="/video/daily-paper/2402.05162-video-overview.mp4" type="video/mp4">
  Your browser does not support the video element.
</video>
<hr>
<h2 id="Ô∏è-mind-map">üó∫Ô∏è Mind Map</h2>
<p><a href="/mindmaps/daily-paper/2402.05162-mindmap.json">Download mind map (JSON)</a></p>
<hr>
<h2 id="-infographic">üìä Infographic</h2>
<p><img src="/images/daily-paper/2402.05162-infographic.png" alt="Infographic: key concepts and findings"></p>
<hr>
<h2 id="abstract">Abstract</h2>
<p>Large language models (LLMs) show inherent brittleness in their safety mechanisms, as evidenced by their susceptibility to jailbreaking and even non-malicious fine-tuning. This study explores this brittleness of safety alignment by leveraging pruning and low-rank modifications. We develop methods to identify critical regions that are vital for safety guardrails, and that are disentangled from utility-relevant regions at both the neuron and rank levels. Surprisingly, the isolated regions we find are sparse, comprising about $3%$ at the parameter level and $2.5%$ at the rank level. Removing these regions compromises safety without significantly impacting utility, corroborating the inherent brittleness of the model‚Äôs safety mechanisms. Moreover, we show that LLMs remain vulnerable to low-cost fine-tuning attacks even when modifications to the safety-critical regions are restricted. These findings underscore the urgent need for more robust safety strategies in LLMs.</p>
<hr>
<h2 id="key-insights">Key Insights</h2>
<h2 id="executive-summary">Executive Summary</h2>
<p>This briefing document analyzes the findings of recent empirical research regarding the structural localization of safety mechanisms in Large Language Models (LLMs). The research demonstrates that safety alignment in models like the Llama2-chat family is remarkably brittle due to its concentration in sparse, identifiable regions. Specifically, safety-critical regions comprise only approximately <strong>3% of parameters</strong> at the neuron level and <strong>2.5% of ranks</strong> at the low-rank level.</p>
<p>The study introduces two primary methods for isolating these regions: <strong>Set Difference</strong> for neurons and <strong>Orthogonal Projection</strong> for ranks. By removing these sparse regions, the research shows that a model‚Äôs safety guardrails can be almost entirely dismantled‚Äîincreasing Attack Success Rates (ASR) from 0% to over 90%‚Äîwhile maintaining the model‚Äôs general utility and linguistic capabilities. Furthermore, the findings suggest that current alignment strategies like Reinforcement Learning from Human Feedback (RLHF) create a ‚Äúsafety wrapper‚Äù that can be easily bypassed by fine-tuning attacks, as the model can develop alternative pathways that circumvent frozen safety-critical parameters.</p>
<h2 id="detailed-analysis-of-key-themes">Detailed Analysis of Key Themes</h2>
<h3 id="1-the-sparsity-of-safety-critical-regions">1. The Sparsity of Safety-Critical Regions</h3>
<p>The central discovery of the research is that safety is not robustly distributed throughout the neural network. Instead, it is localized in extremely sparse regions.</p>
<ul>
<li><strong>Parameter Level:</strong> Only 3% of the weights are vital for safety guardrails.</li>
<li><strong>Rank Level:</strong> Only 2.5% of total ranks contribute exclusively to safety.
This sparsity creates a severe ‚Äúvulnerability surface,‚Äù allowing attackers or even non-malicious fine-tuning to inadvertently or intentionally degrade safety mechanisms without damaging the model‚Äôs core utility.</li>
</ul>
<h3 id="2-disentanglement-of-safety-and-utility">2. Disentanglement of Safety and Utility</h3>
<p>A significant challenge in AI safety research is the ‚Äúintricate overlap‚Äù between safety awareness and general utility. For instance, to decline a harmful request, a model must first understand the request (utility) before refusing it (safety).</p>
<ul>
<li><strong>Set Difference Method:</strong> By comparing importance scores (using SNIP or Wanda) for both safety and utility datasets, researchers isolated neurons that score high for safety but low for utility.</li>
<li><strong>Localization Results:</strong> Removing these isolated regions caused the model to be ‚Äúeffectively jailbroken‚Äù while general instruction-following and zero-shot accuracy remained relatively stable (above 0.5 accuracy).</li>
</ul>
<h3 id="3-layer-wise-behavior-mlp-vs-self-attention">3. Layer-Wise Behavior: MLP vs. Self-Attention</h3>
<p>The research utilized the Jaccard index (neuron level) and subspace similarity (rank level) to measure the overlap of safety and utility behaviors across different transformer blocks.</p>
<ul>
<li><strong>Differentiated Behaviors:</strong> MLP layers exhibit lower Jaccard indices and lower subspace similarity compared to attention layers.</li>
<li><strong>Implication:</strong> This suggests that safety-related knowledge is more clearly differentiated and localized within MLP layers, whereas attention layers show more entanglement between safety and utility.</li>
</ul>
<h3 id="4-resistance-to-protective-measures">4. Resistance to Protective Measures</h3>
<p>The research tested whether freezing the identified 3% of safety-critical neurons could prevent fine-tuning attacks (where a model is fine-tuned on non-malicious data like the Alpaca dataset).</p>
<ul>
<li><strong>Failure of Freezing:</strong> Freezing safety-critical neurons offered resistance only against very minor modifications (e.g., fine-tuning on only 10 examples). When the fine-tuning dataset increased to 100 examples, the ASR reached 0.94 regardless of the frozen weights.</li>
<li><strong>Alternative Pathways:</strong> This indicates that fine-tuning attacks do not necessarily ‚Äúunlearn‚Äù safety but rather create new computational routes that bypass the original safety mechanisms.</li>
</ul>
<h2 id="methodological-overview">Methodological Overview</h2>
<p>The study utilized the following weight attribution and isolation methods to identify critical regions:</p>

























<table><thead><tr><th align="left">Attribution Level</th><th align="left">Importance Scoring Method</th><th align="left">Disentanglement Method</th></tr></thead><tbody><tr><td align="left"><strong>Neuron Level</strong></td><td align="left"><strong>SNIP:</strong> Measures first-order Taylor approximation of loss change.</td><td align="left"><strong>Set Difference:</strong> Identifies neurons in the top-q% of safety but not in the top-p% of utility.</td></tr><tr><td align="left"><strong>Neuron Level</strong></td><td align="left"><strong>Wanda:</strong> Minimizes Frobenius norm of the change to the output.</td><td align="left"><strong>Set Difference:</strong> (As above).</td></tr><tr><td align="left"><strong>Rank Level</strong></td><td align="left"><strong>ActSVD:</strong> Data-aware SVD on layer outputs to find important ranks.</td><td align="left"><strong>Orthogonal Projection:</strong> Removes safety ranks orthogonal to utility ranks.</td></tr></tbody></table>
<h2 id="significant-findings-and-data-points">Significant Findings and Data Points</h2>
<ul>
<li><strong>ASR Escalation:</strong> Removing the isolated 3% of safety neurons pushed the ASR in standard and adversarial scenarios close to 1.0 (100%).</li>
<li><strong>Adversarial Fragility:</strong> Models are even more fragile in adversarial contexts; pruning less than <strong>1% of neurons</strong> can compromise safety while keeping utility accuracy above 0.53.</li>
<li><strong>Safety Enhancement:</strong> Conversely, pruning neurons or ranks identified as <em>least</em> important for safety actually slightly <em>improved</em> the model‚Äôs resistance to jailbreaking (specifically ASRAdv-Decoding).</li>
<li><strong>Attention Head Probing:</strong> Standard probing of attention heads was found insufficient for localizing safety, as achieving high accuracy in predicting harmful vs. harmless instructions did not correlate with the ability to isolate safety-critical neurons.</li>
</ul>
<h2 id="important-quotes-and-context">Important Quotes and Context</h2>
<blockquote>
<p>‚ÄúThe finding that only 3% of parameters are safety-critical creates a severe vulnerability surface‚Äîattackers can efficiently target these regions, and the model remains vulnerable to low-cost fine-tuning attacks even when safety-critical regions are nominally protected.‚Äù</p>
</blockquote>
<ul>
<li><strong>Context:</strong> This highlights why current alignment is considered ‚Äúbrittle‚Äù and why protecting specific weights is insufficient for long-term safety.</li>
</ul>
<blockquote>
<p>‚ÄúRemoving these regions compromises safety without significantly impacting utility, corroborating the inherent brittleness of the model‚Äôs safety mechanisms.‚Äù</p>
</blockquote>
<ul>
<li><strong>Context:</strong> This summarizes the core empirical result of the pruning experiments on the Llama2-chat models.</li>
</ul>
<blockquote>
<p>‚ÄúFine-tuning attacks may create alternative pathways in the original model. Given that safety-critical neurons are sparse, these new routes could bypass the existing safety mechanisms easily.‚Äù</p>
</blockquote>
<ul>
<li><strong>Context:</strong> Explains the failure of ‚Äúweight freezing‚Äù as a defense mechanism against fine-tuning attacks.</li>
</ul>
<blockquote>
<p>‚ÄúMLP layers appear to encode more differentiated behaviors‚Ä¶ suggesting that utility or safety-related knowledge is more differentiated in MLP layers within language models.‚Äù</p>
</blockquote>
<ul>
<li><strong>Context:</strong> Provides a mechanistic insight into <em>where</em> safety knowledge is stored, pointing toward MLP layers as the primary site of safety-utility separation.</li>
</ul>
<h2 id="actionable-insights">Actionable Insights</h2>
<ol>
<li><strong>Develop Distributed Safety Mechanisms:</strong> Since current safety is concentrated in sparse regions (the ‚Äúsafety wrapper‚Äù hypothesis), researchers should prioritize alignment techniques that integrate safety more fundamentally and redundantly throughout the model architecture.</li>
<li><strong>MLP-Focused Red Teaming:</strong> Given the higher differentiation of safety behaviors in MLP layers, red-teaming and weight-attribution efforts should focus more heavily on MLP components rather than just attention heads.</li>
<li><strong>Use Sparsity as a Safety Metric:</strong> The sparsity of safety-critical neurons and ranks can serve as a ‚Äúmodel-intrinsic metric‚Äù for assessing the brittleness of a model‚Äôs alignment, complementing traditional external red-teaming.</li>
<li><strong>Refine Pruning for Defense:</strong> The discovery that removing the ‚Äúleast safety-relevant‚Äù regions can improve robustness suggests that pruning-based approaches could be used as a defensive tool to ‚Äúclean‚Äù models of detrimental or redundant parameters that interfere with safety.</li>
<li><strong>Re-evaluate Fine-tuning APIs:</strong> The ease with which safety is bypassed via alternative pathways during fine-tuning suggests that current ‚Äúsafety-region restrictions‚Äù in commercial fine-tuning APIs may be insufficient to prevent jailbroken states.</li>
</ol>
<hr>
<p><em>Read the <a href="https://arxiv.org/abs/2402.05162">full paper on arXiv</a> ¬∑ <a href="https://arxiv.org/pdf/2402.05162.pdf">PDF</a></em></p>  </div> </article>  </main> <footer class="site-footer" data-astro-cid-sz7xmlte> <div class="footer-inner" data-astro-cid-sz7xmlte> <div class="footer-grid" data-astro-cid-sz7xmlte> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Project</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/" data-astro-cid-sz7xmlte>Home</a></li> <li data-astro-cid-sz7xmlte><a href="/about/" data-astro-cid-sz7xmlte>About</a></li> <li data-astro-cid-sz7xmlte><a href="/manifesto/" data-astro-cid-sz7xmlte>Manifesto</a></li> <li data-astro-cid-sz7xmlte><a href="https://github.com/adrianwedd/failure-first" target="_blank" rel="noopener" data-astro-cid-sz7xmlte>GitHub</a></li> </ul> </div> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Research</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/research/" data-astro-cid-sz7xmlte>Research Hub</a></li> <li data-astro-cid-sz7xmlte><a href="/blog/" data-astro-cid-sz7xmlte>Blog</a></li> <li data-astro-cid-sz7xmlte><a href="/research/moltbook/" data-astro-cid-sz7xmlte>Moltbook</a></li> <li data-astro-cid-sz7xmlte><a href="/results/" data-astro-cid-sz7xmlte>Results</a></li> <li data-astro-cid-sz7xmlte><a href="/rss.xml" data-astro-cid-sz7xmlte>RSS Feed</a></li> </ul> </div> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Contact</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/contact/" data-astro-cid-sz7xmlte>Get Involved</a></li> <li data-astro-cid-sz7xmlte><a href="/about/disclosure/" data-astro-cid-sz7xmlte>Responsible Disclosure</a></li> <li data-astro-cid-sz7xmlte><a href="mailto:research@failurefirst.org" data-astro-cid-sz7xmlte>research@failurefirst.org</a></li> </ul> </div> </div> <div class="footer-bottom" data-astro-cid-sz7xmlte> <p data-astro-cid-sz7xmlte> <strong data-astro-cid-sz7xmlte>Remember:</strong> This is a research tool for improving AI safety.
        Use responsibly. Study failures to build better defenses.
</p> <p class="footer-copyright" data-astro-cid-sz7xmlte>
&copy; 2026 Failure-First Embodied AI Project |
<a href="https://github.com/adrianwedd/failure-first" target="_blank" rel="noopener" data-astro-cid-sz7xmlte>GitHub</a> </p> </div> </div> </footer>   <script type="module">function g(e){let t=e>>>0;return function(){t|=0,t=t+1831565813|0;let n=Math.imul(t^t>>>15,1|t);return n=n+Math.imul(n^n>>>7,61|n)^n,((n^n>>>14)>>>0)/4294967296}}function m(){return Math.floor(new Date/(1e3*60*60*24))*1013}function w(e,t,n,o){const a=Math.ceil(t/60)+2,r=Math.ceil(n/(40*Math.sqrt(3)))+2;e.strokeStyle="rgba(0, 210, 255, 0.03)",e.lineWidth=.5;for(let c=-1;c<r;c++)for(let d=-1;d<a;d++){const l=d*40*1.5,i=c*40*Math.sqrt(3)+(d%2===0?0:40*Math.sqrt(3)/2);o()>.7&&S(e,l,i,40)}}function S(e,t,n,o){e.beginPath();for(let h=0;h<6;h++){const a=Math.PI/3*h-Math.PI/2,r=t+o*Math.cos(a),c=n+o*Math.sin(a);h===0?e.moveTo(r,c):e.lineTo(r,c)}e.closePath(),e.stroke()}function f(e,t,n){e.strokeStyle="rgba(0, 210, 255, 0.02)",e.lineWidth=1;for(let o=0;o<n;o+=4)e.beginPath(),e.moveTo(0,o),e.lineTo(t,o),e.stroke()}class p{constructor(t,n,o){this.x=t,this.y=n,this.phase=o()*Math.PI*2,this.period=8e3+o()*12e3,this.maxRadius=60+o()*40,this.color=o()>.7?"rgba(255, 71, 87,":"rgba(0, 210, 255,",this.birthTime=Date.now()}draw(t,n){const h=(n-this.birthTime)%this.period/this.period,a=Math.sin(h*Math.PI*2)*.5+.5,r=this.maxRadius*a,c=a*.08;t.strokeStyle=`${this.color} ${c})`,t.lineWidth=1,t.beginPath(),t.arc(this.x,this.y,r,0,Math.PI*2),t.stroke(),t.strokeStyle=`${this.color} ${c*.5})`,t.beginPath(),t.arc(this.x,this.y,r*.6,0,Math.PI*2),t.stroke()}}function y(){const e=document.getElementById("sensor-grid-bg");if(!e)return;const t=e.getContext("2d",{alpha:!0}),n=m(),o=g(n);function h(){const i=window.devicePixelRatio||1,s=e.getBoundingClientRect();return e.width=s.width*i,e.height=s.height*i,t.scale(i,i),{w:s.width,h:s.height}}const{w:a,h:r}=h(),c=3+Math.floor(o()*3),d=[];for(let i=0;i<c;i++){const s=o()*a,u=o()*r;d.push(new p(s,u,g(n+i*1013)))}w(t,a,r,o),f(t,a,r);function l(){const{w:i,h:s}=h();t.clearRect(0,0,e.width,e.height),w(t,i,s,o),f(t,i,s);const u=Date.now();for(const M of d)M.draw(t,u);requestAnimationFrame(l)}l(),window.addEventListener("resize",()=>{const{w:i,h:s}=h();w(t,i,s,o),f(t,i,s)})}typeof document<"u"&&(document.readyState==="loading"?document.addEventListener("DOMContentLoaded",y):y());</script></body></html> 
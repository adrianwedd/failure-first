<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><!-- Primary Meta --><title>Comprehensive Sector-Specific NIST AI Risk Management Framework (AI RMF 1.0) Playbook: Humanoid Robotics and VLA-Driven Embodied Systems | Research | Failure-First</title><meta name="description" content="The rapid evolution of humanoid robotics, catalyzed by the convergence of high-performance bipedal mechatronics and Large Language Model (LLM) architectures evolved into Vision-Language-Action (VLA) models, has created a unique class of sociotechnical risk. Unlike traditional industrial robots,..."><link rel="canonical" href="https://failurefirst.org/research/reports/report-22-comprehensive-sector-specific-nist-ai-risk-management-framework-ai/"><meta name="robots" content="index, follow"><meta name="author" content="Adrian Wedd"><meta name="language" content="English"><meta name="theme-color" content="#0a0a0a"><!-- Open Graph --><meta property="og:type" content="article"><meta property="og:title" content="Comprehensive Sector-Specific NIST AI Risk Management Framework (AI RMF 1.0) Playbook: Humanoid Robotics and VLA-Driven Embodied Systems | Research | Failure-First"><meta property="og:description" content="The rapid evolution of humanoid robotics, catalyzed by the convergence of high-performance bipedal mechatronics and Large Language Model (LLM) architectures evolved into Vision-Language-Action (VLA) models, has created a unique class of sociotechnical risk. Unlike traditional industrial robots,..."><meta property="og:url" content="https://failurefirst.org/research/reports/report-22-comprehensive-sector-specific-nist-ai-risk-management-framework-ai/"><meta property="og:site_name" content="Failure-First Embodied AI"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://failurefirst.org/og-image.png"><meta property="og:image:alt" content="Comprehensive Sector-Specific NIST AI Risk Management Framework (AI RMF 1.0) Playbook: Humanoid Robotics and VLA-Driven Embodied Systems | Research | Failure-First - Failure-First Embodied AI"><meta property="og:image:type" content="image/png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@failurefirstai"><meta name="twitter:creator" content="@adrianwedd"><meta name="twitter:title" content="Comprehensive Sector-Specific NIST AI Risk Management Framework (AI RMF 1.0) Playbook: Humanoid Robotics and VLA-Driven Embodied Systems | Research | Failure-First"><meta name="twitter:description" content="The rapid evolution of humanoid robotics, catalyzed by the convergence of high-performance bipedal mechatronics and Large Language Model (LLM) architectures evolved into Vision-Language-Action (VLA) models, has created a unique class of sociotechnical risk. Unlike traditional industrial robots,..."><meta name="twitter:image" content="https://failurefirst.org/og-image.png"><meta name="twitter:image:alt" content="Comprehensive Sector-Specific NIST AI Risk Management Framework (AI RMF 1.0) Playbook: Humanoid Robotics and VLA-Driven Embodied Systems | Research | Failure-First - Failure-First Embodied AI"><meta property="article:published_time" content="2026-02-04"><!-- JSON-LD Structured Data --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Organization","name":"Failure-First Embodied AI","url":"https://failurefirst.org","logo":{"@type":"ImageObject","url":"https://failurefirst.org/og-image.png"},"sameAs":["https://github.com/adrianwedd/failure-first"],"contactPoint":{"@type":"ContactPoint","contactType":"Research Inquiries","url":"https://failurefirst.org/contact/"}}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"ResearchProject","name":"Failure-First Embodied AI","description":"A research framework for characterizing how embodied AI systems fail, degrade, and recover under adversarial pressure.","url":"https://failurefirst.org","sameAs":["https://github.com/adrianwedd/failure-first"],"author":{"@type":"Person","name":"Adrian Wedd"},"sponsor":{"@type":"Organization","name":"Failure-First Embodied AI","url":"https://failurefirst.org"}}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"ScholarlyArticle","headline":"Comprehensive Sector-Specific NIST AI Risk Management Framework (AI RMF 1.0) Playbook: Humanoid Robotics and VLA-Driven Embodied Systems | Research | Failure-First","description":"The rapid evolution of humanoid robotics, catalyzed by the convergence of high-performance bipedal mechatronics and Large Language Model (LLM) architectures evolved into Vision-Language-Action (VLA) models, has created a unique class of sociotechnical risk. Unlike traditional industrial robots,...","url":"https://failurefirst.org/research/reports/report-22-comprehensive-sector-specific-nist-ai-risk-management-framework-ai/","image":"https://failurefirst.org/og-image.png","author":{"@type":"Person","name":"Adrian Wedd"},"publisher":{"@type":"Organization","name":"Failure-First Embodied AI","url":"https://failurefirst.org","logo":{"@type":"ImageObject","url":"https://failurefirst.org/og-image.png"}},"datePublished":"2026-02-04","inLanguage":"en-US","isAccessibleForFree":true}</script><link rel="alternate" type="application/rss+xml" title="Failure-First Embodied AI" href="/rss.xml"><!-- Google Analytics (GA4) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-XXEW64L22D"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-XXEW64L22D');
    </script><style>.report-meta[data-astro-cid-dynbckv2]{display:flex;gap:1rem;flex-wrap:wrap;margin-bottom:2rem;font-family:JetBrains Mono,monospace;font-size:.75rem;text-transform:uppercase;letter-spacing:.04em;color:var(--text-secondary, #888)}.report-number[data-astro-cid-dynbckv2]{color:var(--accent-primary, #f59e0b);font-weight:600}.report-body[data-astro-cid-dynbckv2]{max-width:72ch}.report-body[data-astro-cid-dynbckv2] h2{margin-top:2.5rem}.report-body[data-astro-cid-dynbckv2] table{display:block;overflow-x:auto;-webkit-overflow-scrolling:touch;width:100%;border-collapse:collapse;margin:1.5rem 0;font-size:.875rem}.report-body[data-astro-cid-dynbckv2] th,.report-body[data-astro-cid-dynbckv2] td{padding:.5rem .75rem;border:1px solid var(--border-color, #333);text-align:left}.report-body[data-astro-cid-dynbckv2] th{background:var(--surface-secondary, #1a1a1a);font-weight:600}.report-body[data-astro-cid-dynbckv2] .audio-overview{border-left:3px solid var(--accent-primary, #f59e0b);background:#f59e0b0a;padding:1rem 1.25rem;border-radius:0 6px 6px 0;margin:1.5rem 0}.report-body[data-astro-cid-dynbckv2] .audio-overview p{margin:0 0 .75rem;font-size:.8125rem;color:var(--text-secondary, #888)}.report-body[data-astro-cid-dynbckv2] .audio-overview audio{width:100%;height:40px}
</style>
<link rel="stylesheet" href="/assets/_slug_.BV0HTfXU.css">
<style>.breadcrumbs[data-astro-cid-ilhxcym7]{margin-bottom:1.5rem;font-size:.8125rem;font-family:JetBrains Mono,monospace}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{list-style:none;display:flex;flex-wrap:wrap;gap:0;padding:0}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{color:var(--fg-muted)}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]:not(:last-child):after{content:"/";margin:0 .5rem;color:var(--fg-muted);opacity:.5}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--fg-muted);border-bottom:none}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{color:var(--accent-primary)}.breadcrumbs[data-astro-cid-ilhxcym7] span[data-astro-cid-ilhxcym7][aria-current=page]{color:var(--fg-dim)}
.research-header[data-astro-cid-63t2xjvj]{display:flex;align-items:flex-start;justify-content:space-between;flex-wrap:wrap;gap:.5rem}.status-badge[data-astro-cid-63t2xjvj]{display:inline-block;font-family:JetBrains Mono,monospace;font-size:.6875rem;font-weight:500;text-transform:uppercase;letter-spacing:.06em;padding:.25rem .625rem;border:1px solid var(--badge-color);color:var(--badge-color);border-radius:3px;background:transparent}@media(max-width:480px){.research-header[data-astro-cid-63t2xjvj]{flex-direction:column}}
</style></head> <body> <a href="#main-content" class="skip-link">Skip to content</a> <canvas id="sensor-grid-bg" aria-hidden="true"></canvas> <nav class="site-nav" aria-label="Main navigation" data-astro-cid-pux6a34n> <div class="nav-inner" data-astro-cid-pux6a34n> <a href="/" class="nav-brand" data-astro-cid-pux6a34n> <span class="nav-brand-icon" data-astro-cid-pux6a34n>&#x2B22;</span> <span class="nav-brand-text" data-astro-cid-pux6a34n>F41LUR3-F1R57</span> </a> <button class="nav-toggle" aria-label="Toggle navigation" aria-expanded="false" aria-controls="nav-links" data-astro-cid-pux6a34n> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> <span class="nav-toggle-bar" data-astro-cid-pux6a34n></span> </button> <ul class="nav-links" id="nav-links" role="list" data-astro-cid-pux6a34n> <li class="has-dropdown" data-astro-cid-pux6a34n> <a href="/research/" class="active" aria-current="page" aria-haspopup="true" data-astro-cid-pux6a34n> Research <span class="dropdown-arrow" aria-hidden="true" data-astro-cid-pux6a34n>&#x25BC;</span> </a> <ul class="dropdown" role="list" data-astro-cid-pux6a34n> <li data-astro-cid-pux6a34n> <a href="/research/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>All Studies</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Research hub</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/jailbreak-archaeology/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Jailbreak Archaeology</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>64 scenarios, 6 eras</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/moltbook/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Multi-Agent</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Moltbook analysis</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/attack-taxonomy/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Attack Taxonomy</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>79 techniques</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/research/defense-patterns/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Defense Patterns</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>How models resist</span> </a> </li> </ul> </li><li data-astro-cid-pux6a34n> <a href="/blog/" data-astro-cid-pux6a34n> Blog  </a>  </li><li data-astro-cid-pux6a34n> <a href="/framework/" data-astro-cid-pux6a34n> Framework  </a>  </li><li class="has-dropdown" data-astro-cid-pux6a34n> <a href="/policy/" aria-haspopup="true" data-astro-cid-pux6a34n> Policy <span class="dropdown-arrow" aria-hidden="true" data-astro-cid-pux6a34n>&#x25BC;</span> </a> <ul class="dropdown" role="list" data-astro-cid-pux6a34n> <li data-astro-cid-pux6a34n> <a href="/policy/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Policy Briefs</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>19 reports</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/policy/capability-safety-spectrum/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Capability vs Safety</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>U-shaped curve</span> </a> </li><li data-astro-cid-pux6a34n> <a href="/policy/embodied-ai-safety/" data-astro-cid-pux6a34n> <span class="dropdown-label" data-astro-cid-pux6a34n>Embodied AI Safety</span> <span class="dropdown-desc" data-astro-cid-pux6a34n>Beyond alignment</span> </a> </li> </ul> </li><li data-astro-cid-pux6a34n> <a href="/manifesto/" data-astro-cid-pux6a34n> Manifesto  </a>  </li><li data-astro-cid-pux6a34n> <a href="/about/" data-astro-cid-pux6a34n> About  </a>  </li> </ul> </div> </nav>  <script type="module">const t=document.querySelector(".nav-toggle"),n=document.querySelector(".nav-links"),o=document.querySelectorAll(".has-dropdown");t&&n&&(t.addEventListener("click",()=>{const e=t.getAttribute("aria-expanded")==="true";t.setAttribute("aria-expanded",String(!e)),n.classList.toggle("open")}),document.addEventListener("keydown",e=>{e.key==="Escape"&&n.classList.contains("open")&&(n.classList.remove("open"),t.setAttribute("aria-expanded","false"),t.focus())}),document.addEventListener("click",e=>{n.classList.contains("open")&&!n.contains(e.target)&&!t.contains(e.target)&&(n.classList.remove("open"),t.setAttribute("aria-expanded","false"))}));o.forEach(e=>{const s=e.querySelector(":scope > a");s&&window.innerWidth<=768&&s.addEventListener("click",i=>{window.innerWidth<=768&&(i.preventDefault(),e.classList.toggle("mobile-open"))})});</script> <main id="main-content">  <div class="research-header" data-astro-cid-63t2xjvj> <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7><a href="/" data-astro-cid-ilhxcym7>Home</a></li> <li data-astro-cid-ilhxcym7> <a href="/research/" data-astro-cid-ilhxcym7>Research</a> </li><li data-astro-cid-ilhxcym7> <a href="/research/reports/" data-astro-cid-ilhxcym7>Policy Reports</a> </li><li data-astro-cid-ilhxcym7> <span aria-current="page" data-astro-cid-ilhxcym7>Report 22</span> </li> </ol> </nav> <!-- BreadcrumbList Schema.org structured data --> <script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://failurefirst.org/"},{"@type":"ListItem","position":2,"name":"Research","item":"https://failurefirst.org/research/"},{"@type":"ListItem","position":3,"name":"Policy Reports","item":"https://failurefirst.org/research/reports/"},{"@type":"ListItem","position":4,"name":"Report 22"}]}</script>  <div class="research-status" data-astro-cid-63t2xjvj> <span class="status-badge" style="--badge-color: var(--failure-warning)" data-astro-cid-63t2xjvj> Draft </span> </div> </div>  <article class="report-content" data-astro-cid-dynbckv2> <header class="report-meta" data-astro-cid-dynbckv2> <span class="report-number" data-astro-cid-dynbckv2>Report 22</span>  <span class="report-classification" data-astro-cid-dynbckv2>Standards Development</span> <time class="report-date" data-astro-cid-dynbckv2>2026-02-04</time> </header> <div class="report-body" data-astro-cid-dynbckv2> <h1 id="comprehensive-sector-specific-nist-ai-risk-management-framework-ai-rmf-10-playbook-humanoid-robotics-and-vla-driven-embodied-systems"><strong>Comprehensive Sector-Specific NIST AI Risk Management Framework (AI RMF 1.0) Playbook: Humanoid Robotics and VLA-Driven Embodied Systems</strong></h1>
<hr>
<p>The rapid evolution of humanoid robotics, catalyzed by the convergence of high-performance bipedal mechatronics and Large Language Model (LLM) architectures evolved into Vision-Language-Action (VLA) models, has created a unique class of sociotechnical risk.1 Unlike traditional industrial robots, which operate in caged, deterministic environments, modern humanoid systems are designed for high-dexterity tasks in unstructured human workspaces.4 These “embodied” AI systems do not merely process data; they transform semantic intent—often expressed in natural language—into kinetic force.3 This direct mapping from digital reasoning to physical motion necessitates a specialized application of the NIST AI Risk Management Framework (AI RMF 1.0) that prioritizes physical safety, semantic grounding, and the peculiar vulnerabilities of transformer-based control policies.1</p>
<p>Existing NIST playbooks for financial services and healthcare provide essential structural foundations but fail to address the kinetic consequences and bipedal stability risks inherent to the robotics sector.1 In finance, risk management centers on algorithmic bias in credit scoring and data privacy; in humanoid robotics, these concerns are eclipsed by the potential for high-velocity impacts, catastrophic falls, and the “semantic hallucinations” that lead to unintended physical interventions.9 This playbook operationalizes the four core functions of the AI RMF—GOVERN, MAP, MEASURE, and MANAGE—to provide an exhaustive guide for developers, deployers, and risk officers in the humanoid robotics industry.</p>
<h2 id="govern-organizational-context-and-kinetic-safety-governance"><strong>GOVERN: Organizational Context and Kinetic Safety Governance</strong></h2>
<p>The GOVERN function establishes the institutional foundation for a culture of risk management, defining the accountability structures, legal awareness, and risk tolerances necessary to deploy humanoid systems responsibly.10 Governance in the robotics sector must transcend standard IT oversight to include physical safety engineering and biomechanical liability.9</p>
<h3 id="board-level-safety-governance-and-oversight-structures"><strong>Board-Level Safety Governance and Oversight Structures</strong></h3>
<p>Effective governance begins with clear leadership roles that bridge the gap between AI development and physical safety.10 Humanoid robotics organizations must move beyond the traditional Chief Technology Officer (CTO) model to integrate safety as a board-level imperative.15 This involves defining oversight responsibilities that hold executives accountable for both the digital and physical outcomes of the AI systems they deploy.10</p>
<p>Strategic governance involves the establishment of an AI Ethics and Compliance Committee, which should be multidisciplinary in nature.15 This committee is tasked with reviewing and approving AI governance frameworks, monitoring significant implementations, and ensuring that the organization’s risk tolerance is clearly defined and documented.15</p>





























<table><thead><tr><th align="left">Governance Role</th><th align="left">Specific Responsibilities for Humanoid Robotics</th></tr></thead><tbody><tr><td align="left"><strong>Chief Safety Officer (CSO)</strong></td><td align="left">Oversees physical safety compliance, kinetic risk assessments, and adherence to OSHA/ISO standards.14</td></tr><tr><td align="left"><strong>Chief Risk Officer (CRO)</strong></td><td align="left">Integrates AI-specific risks into the corporate risk register and oversees VLA-driven policy audits.15</td></tr><tr><td align="left"><strong>Chief Technology Officer (CTO)</strong></td><td align="left">Leads VLA development, model training, and technical governance of the embodied intelligence stack.3</td></tr><tr><td align="left"><strong>Board AI Oversight</strong></td><td align="left">Approves the organization’s kinetic risk tolerance levels and monitors high-impact humanoid deployments.15</td></tr><tr><td align="left"><strong>Legal Counsel</strong></td><td align="left">Advises on the evolving regulatory landscape, including the EU AI Act and liability frameworks for autonomous bipedal systems.15</td></tr></tbody></table>
<p>The governance structure must also prioritize “Trustworthy AI” characteristics, such as validity, reliability, safety, and accountability.8 In robotics, “reliability” specifically refers to the robot’s ability to maintain active stability and complete tasks without unintended stoppages or hazardous falls.8</p>
<h3 id="incident-reporting-and-near-miss-frameworks"><strong>Incident Reporting and Near-Miss Frameworks</strong></h3>
<p>A core component of the GOVERN function is the establishment of robust incident reporting mechanisms.10 For humanoid robotics, the reporting threshold must be extremely low to capture “near misses”—unplanned events that could have caused physical injury or property damage but did not.21 Near misses in the robotics sector often involve “latent system deficiencies,” such as a VLA model nearly misidentifying a person as an object, or an actuator showing signs of “gait drift” before a fall occurs.24</p>
<p>Effective reporting requires a “no-blame” culture where employees feel safe sharing information about failures or close calls.25 The goal is to turn “close calls” into “proactive safety improvements” through root cause analysis.21 Organizations should implement a reporting form that is concise, taking less than five minutes to complete, to ensure high participation rates.25</p>
<h3 id="safety-culture-metrics-and-leading-indicators"><strong>Safety Culture Metrics and Leading Indicators</strong></h3>
<p>Governance must be informed by objective data regarding the organization’s safety performance.8 Traditional lagging indicators, such as injury rates, are insufficient for predicting failures in complex AI systems.23 Instead, robotics companies must track leading indicators that reflect the health of the safety culture and the reliability of the AI-machine interface.23</p>



































<table><thead><tr><th align="left">Safety Metric</th><th align="left">Definition</th><th align="left">Strategic Significance for Robotics</th></tr></thead><tbody><tr><td align="left"><strong>Near Miss Rate (NMR)</strong></td><td align="left">Frequency of events that almost led to a physical or digital failure.21</td><td align="left">High NMR with high reporting indicates a strong safety culture and a rich data source for mitigation.25</td></tr><tr><td align="left"><strong>Training Completion Rate (TCR)</strong></td><td align="left">Percentage of staff trained in VLA safety and kinetic risk protocols.23</td><td align="left">High TCR correlates with lower incident rates and better handling of edge cases.23</td></tr><tr><td align="left"><strong>Audit Frequency</strong></td><td align="left">Number of regular bias, privacy, and safety audits conducted per quarter.10</td><td align="left">Ensures continuous monitoring and helps align internal practices with the NIST framework.10</td></tr><tr><td align="left"><strong>Mean Time to Acknowledge (MTTA)</strong></td><td align="left">The average time for the safety team to acknowledge a reported AI anomaly.28</td><td align="left">Reflects the organization’s responsiveness to emerging technical or safety risks.28</td></tr><tr><td align="left"><strong>Safety Audit Submission Rate</strong></td><td align="left">The ratio of completed safety audits to planned checks in the manufacturing or deployment site.23</td><td align="left">Indicates the level of compliance with established safety management systems.23</td></tr></tbody></table>
<h3 id="risk-tolerance-for-kinetic-consequences"><strong>Risk Tolerance for Kinetic Consequences</strong></h3>
<p>The “Risk Tolerance” component of the GOVERN function is the board’s agreement on the level of physical and digital risk the organization is willing to accept to achieve its goals.13 In humanoid robotics, this involves setting specific thresholds for kinetic impacts.20 Unlike the financial sector, where risk tolerance might involve a percentage of financial loss, robotics risk tolerance is governed by biomechanical limits.17</p>
<p>Organizations must adhere to standards like ISO/TS 15066, which defines the “Power and Force Limiting” (PFL) mode.29 This mode ensures that robots do not exceed pain or injury thresholds during human-robot interaction.29 The board must decide whether the robot is permitted to operate in “collaborative” mode (interacting directly with humans) or must remain “separated,” as seen in early-stage humanoid demos at events like CES.6</p>
<h2 id="map-context-risk-identification-and-the-semantic-kinetic-nexus"><strong>MAP: Context, Risk Identification, and the Semantic-Kinetic Nexus</strong></h2>
<p>The MAP function identifies the specific risks, impacts, and stakeholders associated with the humanoid robot’s deployment.8 For VLA-driven systems, mapping requires a deep understanding of how multimodal inputs (vision and language) can be manipulated to produce hazardous physical actions.7</p>
<h3 id="sector-specific-risk-taxonomy"><strong>Sector-Specific Risk Taxonomy</strong></h3>
<p>Humanoid robotics risks are multifaceted, spanning mechanical, cognitive, and social domains.1 A comprehensive risk taxonomy for this sector includes:</p>
<ul>
<li><strong>Kinematic Risks</strong>: Mechanical failures involving the robot’s physical structure, such as joint lockups, motor overheating, or the loss of “active stability”.4 Because bipedal humanoids have no “passive” stable state, power loss leads to an immediate collapse, posing a significant injury risk to nearby people.6</li>
<li><strong>Semantic Risks</strong>: Grounding failures where the VLA model misinterprets environmental context or natural language instructions.1 This includes the “Semantic-Kinetic Gap,” where a linguistically plausible instruction (e.g., “Hand me the knife”) leads to an unsafe physical trajectory (e.g., pointing the blade toward the human).3</li>
<li><strong>Cognitive Risks</strong>: Planning failures in long-horizon tasks.35 This includes the “Memory Trap,” where a VLA model repeats a previously learned trajectory despite a change in the physical environment (e.g., an object has moved), potentially causing a collision or a fall.7</li>
<li><strong>Social and Psychological Risks</strong>: The anthropomorphic form of humanoids can lead to social manipulation or privacy concerns.1 Humanoids equipped with pervasive sensors (cameras, microphones) in domestic settings create massive vulnerabilities for personal espionage or data breaches.1</li>
<li><strong>Supply Chain Risks</strong>: Vulnerabilities in the specialized components (actuators, sensors) or the “Byzantine” risks associated with third-party pre-trained models.4 Compromised hardware or training data can introduce backdoors that bypass safety guardrails.9</li>
</ul>
<h3 id="vla-threat-modeling-and-multimodal-adversarial-attacks"><strong>VLA Threat Modeling and Multimodal Adversarial Attacks</strong></h3>
<p>Threat modeling for humanoid systems must account for the susceptibility of VLA models to adversarial perturbations across multiple modalities.33 Unlike standard LLMs, where the output is text, VLA failures manifest as physical harm.33</p>



































<table><thead><tr><th align="left">Attack Category</th><th align="left">Mechanism</th><th align="left">Physical Consequence in Robotics</th></tr></thead><tbody><tr><td align="left"><strong>Adversarial Visual Patches</strong></td><td align="left">Small, crafted images (white-box optimized) placed on objects or the robot’s own arm.39</td><td align="left">Can “freeze” the robot (FreezeVLA) or cause it to execute high-velocity, unintended movements.35</td></tr><tr><td align="left"><strong>Typographic Attacks</strong></td><td align="left">Textual instructions placed in the visual scene (e.g., a sign that says “Stop” or “Kick”).33</td><td align="left">The VLA may interpret the visual text as a command, bypassing legitimate instructional prompts.33</td></tr><tr><td align="left"><strong>Prompt Injection</strong></td><td align="left">Malicious suffixes or prefixes in the language instruction.39</td><td align="left">Can cause the model to ignore safety constraints, leading to collisions or the handling of prohibited objects.35</td></tr><tr><td align="left"><strong>Cross-Modal Misalignment</strong></td><td align="left">Intentional disruption of the semantic correspondence between vision and action.39</td><td align="left">Leads to the robot performing the correct <em>action</em> on the wrong <em>object</em> (e.g., putting a glass cup in a shredder).33</td></tr><tr><td align="left"><strong>FreezeVLA Inaction</strong></td><td align="left">Adversarial images designed to maximize the likelihood of “zero-action” outputs.35</td><td align="left">Disconnects the “digital mind” from physical action, potentially paralyzing the robot during a critical safety intervention.35</td></tr></tbody></table>
<h3 id="stakeholder-mapping-and-responsibility-chains"><strong>Stakeholder Mapping and Responsibility Chains</strong></h3>
<p>Identifying the “AI actors” across the humanoid lifecycle is critical for assigning accountability.13 This mapping must identify the developers of the VLA, the manufacturers of the mechatronics, the deployers (e.g., a warehouse operator), and the end-users (e.g., human coworkers).4</p>



































<table><thead><tr><th align="left">Stakeholder Group</th><th align="left">Primary Risk Concerns</th><th align="left">Role in the AI RMF</th></tr></thead><tbody><tr><td align="left"><strong>VLA Developers</strong></td><td align="left">Model robustness, adversarial resistance, and semantic grounding.3</td><td align="left">Responsible for MAP and MEASURE during training and pre-deployment.13</td></tr><tr><td align="left"><strong>Robot Manufacturers</strong></td><td align="left">Mechanical reliability, battery safety, and kinetic guardrails.4</td><td align="left">Responsible for GOVERN and MAP regarding hardware and mechatronic failure modes.4</td></tr><tr><td align="left"><strong>Deployment Operators</strong></td><td align="left">ODD compliance, workforce training, and site-specific hazards.4</td><td align="left">Primary actors for MANAGE; responsible for real-time monitoring and incident response.8</td></tr><tr><td align="left"><strong>End-Users (Humans)</strong></td><td align="left">Physical safety, psychological stress, and ergonomics.6</td><td align="left">Provide feedback for MEASURE and are the primary beneficiaries of the framework.8</td></tr><tr><td align="left"><strong>Insurance Providers</strong></td><td align="left">Liability underwriting and dynamic pricing based on safety KPIs.18</td><td align="left">Facilitate risk transfer and require data transparency from deployers.38</td></tr></tbody></table>
<h3 id="operational-design-domain-odd-specification"><strong>Operational Design Domain (ODD) Specification</strong></h3>
<p>A humanoid’s safety is inextricably linked to its ODD—the environment and conditions for which it was designed.6 Mapping the ODD involves specifying the physical limits of the workspace.4</p>
<ul>
<li><strong>Environmental Constraints</strong>: Specifying floor surface types (carpet vs. concrete), lighting levels (<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAC4AAAAYCAYAAACFms+HAAACZUlEQVR4Xu2WS6hNURzGP+9X5BpIGFx5pDC4LhkonUTMJAMDJRQT5ZGbunXLROY3BsrAOwpF3iITeU1J3q4YKI+8HyV8n//aztr/sx9nYKDsX/06e69vrbXX3nuttQ9QUfF/MZc+ok/og3D8kJ6LKwXO06ewuvIxPRLl6+gzWHt5j46NcjEO1rYn+lU/40O+K5xrLFJ9DAxZJifoT7rIB44arJ5uonc6+k0r/UYX037pKMVCWD+v6IiofCh9T4/RJXRQlGXyAtagrw8cHbALrvdBYAK97gtzuA3rqxaV7aBd0Xkhk2AdnPZBBidhdaf5ILCKbvOFOWhqqa+D4byTbq/H5ayGdaCnWYSmxlv6kvZyWcJeOt8X5tBCv9CvdBM9jOzpl4vuWAOf4QPHdFi9oz6IuE+H+MIC9sP6vEb7u6yU57An2ccHjo2wi6z1QaCVXvGFJayE9XnHB2VMhDU85YPAcNSfRLLzTKnHKVbQrb6wgMn0JmzLU7+z03Exa2CNNvsgcJyOhM3pN/R1OM5iN53nC3MYAxu0dqFkke5L1SjhEKzRLB+QqfRMOB4Fq5f1YRKj6S00N0+1KK/C1kxy/hm2UHXcFNq/P6Bx/x5AL9Bl4XwwbPVrO8ziLOztlaF+LqPxzWg30oPJ+z6kaEP2U2ynl+hHpHeIA7DBa94naEFvoTujsiw0vbRraXp0u0wsgI3lLhof4h/mwP4PfIJV1mvqgf0P0Rz+Qb/D5mzMMHoR9pb0hdMAbsD24KIdaSns067r6Mb1W4vyDbC3rqmi7B3dE+V/jZl0OexD0/ScrKioqPi3+AU0SIk7pUL+awAAAABJRU5ErkJggg==" alt="">), and the presence of particulate matter (dust) that could foul sensors.4</li>
<li><strong>Dynamic Actor Density</strong>: Defining the maximum number of humans allowed per square meter and their expected behavior (e.g., trained workers vs. unpredictable members of the public).6</li>
<li><strong>Functional Thresholds</strong>: Defining the maximum payload, maximum walking speed, and the specific battery level at which the robot must initiate a “Safe-Shutdown” procedure.4</li>
<li><strong>Force and Power Limits</strong>: Explicitly documenting the biomechanical limits for different body locations, as per ISO/TS 15066, based on whether the contact is “impact” (transient) or “pinching” (quasi-static).30</li>
</ul>
<h2 id="measure-risk-assessment-quantitative-metrics-and-reliability"><strong>MEASURE: Risk Assessment, Quantitative Metrics, and Reliability</strong></h2>
<p>The MEASURE function employs quantitative and qualitative tools to analyze and track the risks identified in the MAP function.8 In the humanoid sector, measurement must bridge the gap between digital performance (e.g., model accuracy) and physical reliability (e.g., gait stability).8</p>
<h3 id="quantitative-metrics-for-vla-driven-humanoids"><strong>Quantitative Metrics for VLA-Driven Humanoids</strong></h3>
<p>Humanoid robotics requires a new family of metrics that reflect the unique challenges of embodied AI.33 Standard accuracy metrics do not account for the “Memory Trap” or the physical consequences of a delayed response.7</p>
<ol>
<li><strong>Time-to-Failure (TTF)</strong>: The average duration of autonomous operation between interventions required to prevent a safety incident.12</li>
<li><strong>Recovery Score (RS)</strong>: A metric (0-100%) reflecting the robot’s success in independent fall recovery or “semantic re-grounding” after a VLA error.4</li>
<li><strong>Human Reentry Latency (HRL)</strong>: The time (<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABoAAAAYCAYAAADkgu3FAAABgUlEQVR4Xu2TTShvQRiHXx9FuuRrxSVFSYpYKQtSLG7Z2VhIxEpSLMTdsVBYKBbIRsq92XBLyN4WS0lRNj4iJSuJ5/2/c9z5z3+rbM5TT535zZl558yZEYmJifkqMrEdS107AxuwA39EL0Et/sI8LwvJxmaxsflBn/zFFXwSK7iDk7iMj1iOs7iA4/iCrTowoAqPcR4n8FRsbIIWnMJqfMdLLHZ9+jWaPWCTy5QT3PTaEas4457LxBbUFXUOYA32iE2qhSMqXfbby5Qb3Agy5RaPsA2LsBezkt6ANbGtS/eyPrFC9V5W57J+L4uYE+tT78Q+IIUL3A2ydbF/5Befxlf5v70+OTiIf/BNbM4k9LTpKsaC/Aq3g+wcD9zzEhaKncZrsa2KWMQzr52gW6yQHumICpcNe5lOqtmo2P/bcvkI3mOja+v10MUMufYnelK0epqXdeKz2IQ+e7iPh1jiMl2AZlpYr8A/seOdQq7Y/oYUhIFDj65e8hB9/2cYxsR8Dx8BR0aJw1PKQgAAAABJRU5ErkJggg==" alt="">) required for a human supervisor to detect a failure and successfully take control of the robot’s actuators.28</li>
<li><strong>Semantic Alignment Score (SAS)</strong>: A mechanistic probe quantifying how well the hidden states <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAAYCAYAAAAcYhYyAAABKklEQVR4Xt2UvStGcRTHD3nL2yQvUf4JRVYTgywko6IMNmUgm8VEGTAwGSQzzyCLwcoisvgHDIhk4HM6N849jx73tz6f+tS93/Pr3Pt7uVek6mnDlhgWZQM/8AuXQi2JebEmQ7GQwi6+YF0spHCHZzFMoUdsKsvYiaPYnxtRgGmxJkd4jAv4gOt+0H/siDVZcZk2eMJal1XkFi9Dti/WJFKTmaNLyt9CecSTkCmHOBbDKbEmwy4bzLIZlym6/XoMdCNybOMr1rtsC9+xFSdxAmfxAN9wE/t+RsMNlnwAV3guNvcLse9JH7KGe9j0O1SkAT9xzoewiNdijUZcfip2HMrojkFGB7a7e12PZ/ljPVIYwPvsehWbXa0wvWLfl/42xkMtCV3QxhhWEd+HGzIQQv+4jQAAAABJRU5ErkJggg==" alt=""> of a VLA generated action align with the embeddings <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAYCAYAAAAlBadpAAABEklEQVR4Xu2SLUtEURCGR9ePuGJdTIKIuEUMJrHrLzCrCBssWxZMYttlk92gBg2LxsXgDxBsBhFEEfzIWmSDPrMzR+ZeVs2iDzxh3jP3njnnXpF//ipDOI8z+YWfWMZHrOE+HuE1DsamXqziG5a97sMbvE0NX1HCF9zN5c9iEyQmcTHUXdbwHZdCNuWZriXWxSbMsCfWOBqyimcTIevJjtiIkWN8CLXuuiV2FxkWsIMjXlfFdj3wWs+pn+5K7NwZ+rGOl3iKDbGHV3x9Fqfxznu/JZ13PGT6wu1Qd9FxmjgcsjM8D7Xu9iR2efoDfdLGVyxiATfxXuzbJ/SSLnBDcr/tHLbwBA+9YSw2OAOSne638gGtyS7MRbnmOQAAAABJRU5ErkJggg==" alt=""> of the physical scene objects.34
<ul>
<li>Formula: <img src="data:image/png;base64,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" alt="">.48</li>
</ul>
</li>
<li><strong>Attack Success Rate (ASR)</strong>: The percentage of adversarial attempts that successfully trigger a “Freeze” state or an unsafe kinetic action.35 For example, OpenVLA has been shown to have a 95.4% ASR under certain “FreezeVLA” conditions.35</li>
<li><strong>Mean Time Between Failures (MTBF)</strong>: Measures the time between system collapses or shutdowns during normal operations, used as an indicator of mechatronic end-of-life.28</li>
</ol>
<h3 id="red-teaming-for-embodied-ai"><strong>Red Teaming for Embodied AI</strong></h3>
<p>Measurement must include rigorous red teaming that focuses on the physical-digital intersection.33 This involves simulating adversarial scenarios that are specific to robotics.33</p>
<ul>
<li><strong>Proprioception Hijacking</strong>: Attempting to trick the VLA into a “wrong state” by providing deceptive sensory data about its own limb positions.9</li>
<li><strong>OOD (Out-of-Distribution) Stress Testing</strong>: Introducing novel objects or environmental conditions (e.g., strobe lights, smoke) to identify the “Memory Trap” threshold where the VLA reverts to memorized, unsafe trajectories.7</li>
<li><strong>Force Limit Override</strong>: Attempting to use natural language prompts to bypass software-level power and force limits (PFL), testing the resilience of the safety guardrails.31</li>
</ul>
<h3 id="continuous-monitoring-and-failure-prediction"><strong>Continuous Monitoring and Failure Prediction</strong></h3>
<p>Humanoid robots require real-time monitoring to detect failures before they result in harm.45 Frameworks like FIPER (Failure Prediction at Runtime) use conformal prediction to distinguish actual failures from benign OOD situations.45</p>






























<table><thead><tr><th align="left">Monitoring Tool</th><th align="left">Mechanism</th><th align="left">Application in Robotics</th></tr></thead><tbody><tr><td align="left"><strong>Conformal Prediction</strong></td><td align="left">Calibrates uncertainty estimates on action token outputs.49</td><td align="left">Detects outliers or unsafe states <em>before</em> the VLA executes the physical action.49</td></tr><tr><td align="left"><strong>FIPER Framework</strong></td><td align="left">Aggregates failure indicators over short time windows.45</td><td align="left">Triggers a failure alarm without requiring extensive “failure data” for training.45</td></tr><tr><td align="left"><strong>Neuro-Ergonomic Streams</strong></td><td align="left">Merges ROS (Robot Operating System) messages with human physiological data.47</td><td align="left">Creates “collaboration twins” that update collision envelopes in under <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAVCAYAAAA0GqweAAACQklEQVR4Xu2VS4iNcRjGH7eSXCI17o1LJDUaSqwMuRSxs7CQiB2pMTXFzpTrxsJiRlLTILeQ3JPFZJZY2AhlhCKRSBNTeJ7e/995z3t8snBKOr/6NX3P9535nvO/HaBGjX+Peroxho5pdBvdS1eHe1VjNt1P79Fv9Gr57Z8soc/pDrqU3qFnyp6oEgvoZjqffsGvCw6iL2mLy8bQT/j9iP91igqupd/pvJDfpbdDVlWKCh6GFZwa8suwzwxO1/q7nE5M1xr5RrqCDk+ZmENX0ZEuiwyNgSgqeBJWcHzIz6W8Ll2fph30A6zoJbqLttP3dAo9CPvCrfQzbdIHAzPo/RiKooI3UV4ko02iXBttMd1DZ6XsGR2bntPoKXtHF6ZMPKCn3HXmKN0XQ6GC12JIbsBeMC7kueBMugVWdEPKVDgzPWW7XSZe066QiTe0J4ZCBa/HkJyAvSCvrcz5lGtHZ47BpnigyzbBnpvrsoaU6QSJHILdq6Co4AGUptJzC7aOBrjsKb3irkUnbA360m20H6Vl4BlGt8ZQqKCmM9IEK7gy5I/oBXetEdZzO10meunFkD1G6V1HYLOg3f0CBWfrEPqVdqN0bGR0XDyE7b6M1l0fXeay9bCCOloy9Snb7jKVUdYMW59nU65fqbcI563Ooyf0Ff2Y1CLVNxzlntMR0UuPw/6xplKFPNp5GlU/5Wtgvzgq4tFm1HLSMpmQMhVXpsJ+MP4Yjewiug6VZ6IYAVs/kdExSExG5WwJPT8phjX+O34AZAZ9y3ByoE4AAAAASUVORK5CYII=" alt="">.47</td></tr><tr><td align="left"><strong>Edge Compute Dashboards</strong></td><td align="left">Provides real-time visibility into joint torques and VLA confidence.4</td><td align="left">Allows on-site supervisors to intervene when the robot enters a high-risk operational state.15</td></tr></tbody></table>
<h3 id="the-measurement-reliability-problem"><strong>The Measurement Reliability Problem</strong></h3>
<p>A significant challenge in the robotics sector is the “Measurement Reliability Problem”—the lack of consensus on how to measure the “trustworthiness” of bipedal autonomous systems.9 Because humanoid VLAs are trained on massive, “black-box” datasets, their behavior in the “real world” is often inscrutable.9</p>
<p>This problem is exacerbated by the “Human Baseline” challenge: there is no clear standard for how safely a human performs these same tasks, making comparative risk assessment difficult.20 Organizations must document which trustworthiness characteristics are <em>not</em> being measured and the justification for their exclusion to maintain transparency.13</p>
<h2 id="manage-risk-response-rollback-and-containment"><strong>MANAGE: Risk Response, Rollback, and Containment</strong></h2>
<p>The MANAGE function involves the allocation of resources to respond to the risks identified and measured in previous functions.8 For humanoid robotics, management requires a multilayered response architecture that can handle both digital VLA failures and mechanical mechatronic faults.4</p>
<h3 id="response-protocols-and-fallback-procedures"><strong>Response Protocols and Fallback Procedures</strong></h3>
<p>Humanoid systems must have pre-defined fallback states for when an AI anomaly or a mechanical fault is detected.6</p>
<ol>
<li><strong>Safe-Shutdown (Squat-to-Rest)</strong>: Because bipedal robots collapse when power is disconnected, a “safe-shutdown” framework involves the robot proactively lowering its center of gravity to a stable, seated position before powering down.6</li>
<li><strong>Fail-Operational (Slowbot Mode)</strong>: In scenarios where the environment is too complex for high-speed operation, the robot transitions to a reduced-velocity mode (<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFEAAAAYCAYAAACC2BGSAAADl0lEQVR4Xu2XWahOURTHl3mWechQiChFeMCDKZGMJbmGujdJ5jkkeRESZQgpY8ZERBQSkTHxwAshc15MkbHE/3/XOexvfft837n3+u4l51f/uve/z3fO3uusvfY6IgkJCX8vta2RUDR6QSusWZa0hqaLTmqwGYtDDWieNXPMdqizNcuKvtATaBbUDzoHHUy5wk9daBF0FvoCfUwdzinVoCvWzAUNrOGhAvQcmu949aAPUL7j+WgEzYB6QxeldIM4RvQF5oxO0B7oEFTFjFmGQT+gLsa/JJphcTktpRvEk1BLa/4JmBEnoL1QRzMWxTrRILYy/nHoK1TR+FFkCmIb0bmVD/5vCA2C2v+6QqQWNEA0AbLRRDK/4HKitXIo1MKMeeEPeDHr2BbRA6Io7BMNYlPjM4vpNzZ+FFFB7CH6Up9Bm0TrLuvtVOgRtDy45mjgXYDOFP4ymjnQBGsGcOedEl3XTOiqaHy8sJaNhS5DqyU9CHHh4n3B4kLpdzB+FFFB5LarCR0QvZ9be9dA30SfxWQgw0Wvaxde5IEHSlR/yJgwcIT3vA1t/D2sVIYmQdegpaInZEngW+OkuUVcwiBmWowLg/jJeJzryuDvh6K7xWU39EZ0K4dMEX0uS4APlqlMnQPHXkKjRe87XtLXVpj6L6AFUFUzVhy41TjpZsY/HPg8qePAIH62ZkBz0XvZPpJtFbexyxHoqfFcVkFDrOnAHpfPopjlPMW9MHjToOvQQolO7ThwUr5ty7rE7Rlus2xkCiKzgc/o5ng8yOjNdjxmDrN5reO58GC6JdkPuxGi9fe16OEYldWF8Gb5onVxmcTrCy19RBcz0Ph3RbPCpStUyXghDCIbbh9boXeidTykQPS57mnMekavu+jJzXLlwg+B9cYL4bxuiH7FhIwUf6nywmxh9M+LtizcPnHhwu6I/i6EdZBZ1d/xCkQntM3xXPhsbh8eIpZ70DHj7YJeSWqmb4DeimbcDklvd3ZKaja78Fpm3UTHWyLaZRQZvi32ilxsWzMWBZvWx6ITnws9kPRa0lO0TWHhD6kP3RdtVd4HYhCYxWFm8/PsOzQu+D/kJrTZeJw76yF3AL+EXHgflq8oGHjej90Ay8F+0TYn28dGRthssm+Me/iwNPDQGiXFb5ei8G2nOtYIqC7p7RbJgxZb0wPXy145bOwTHPgFlZPPvP8Flg0eXAklYLLowZZQAhhE36mfkPCP8hOZF6+qbk3APwAAAABJRU5ErkJggg==" alt="">) where all kinetic energy is kept below injury thresholds, regardless of VLA output.6</li>
<li><strong>Mechanical Compliance</strong>: Utilizing limbs with spring-like properties (“compliant joints”) that mechanically limit impact forces, providing a hardware-level safety net that cannot be bypassed by software or AI.4</li>
</ol>
<h3 id="human-in-the-loop-hitl-and-policy-rollback"><strong>Human-in-the-Loop (HITL) and Policy Rollback</strong></h3>
<p>Humanoid VLAs require “Online Policy Rectification” mechanisms to correct errors in real-time.36</p>
<ul>
<li><strong>VLA-in-the-Loop Framework</strong>: A system that introduces an “online intervention mechanism” using a lightweight World Model (WM).36 The WM evaluates the feasibility of a proposed action (e.g., a grasp) and “imagines” a successful outcome.36 If the proposed action is deemed unsafe, the system intervenes to correct the base VLA policy.36</li>
<li><strong>Historical Rollback via Affordance</strong>: When a “Memory Trap” or planning failure is detected (e.g., through proprioception monitoring), the system “rolls back” the robot to a recent “high-affordance” position.7
<ul>
<li>Rollback Target Formula: <img src="data:image/png;base64,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" alt="">.7</li>
<li>This repositions the robot to a safer, low-cost state to mitigate the immediate effects of a VLA failure.7</li>
</ul>
</li>
</ul>
<h3 id="multi-agent-containment-and-byzantine-resilience"><strong>Multi-Agent Containment and Byzantine Resilience</strong></h3>
<p>In environments with multiple humanoid units (e.g., a warehouse robot fleet), the risk of “fleet-wide compromise” must be managed.51</p>
<ul>
<li><strong>Decentralized Blocklist Protocol (DBP)</strong>: A method for managing “Byzantine” faults—compromised robots that misbehave in arbitrary ways.37 Robots use peer-to-peer communication to accuse and independently verify misbehaving peers based on physical possibility (e.g., a robot reporting a location that is impossible to reach).37</li>
<li><strong>Accusation-Based Containment</strong>: Once a robot is “blocked,” its influence is removed from the fleet’s coordinated decision-making, allowing the remaining cooperative robots to continue operations.37</li>
<li><strong>Communication Scalability</strong>: Using “Task-Oriented Communication” to prioritize critical safety data over less urgent environmental updates, preventing network congestion that could delay emergency stops.52</li>
</ul>
<h3 id="insurance-integration-and-risk-transfer"><strong>Insurance Integration and Risk Transfer</strong></h3>
<p>The “Manage” function also involves financial risk treatment through insurance.18 Humanoid robotics presents a convergence of physical and digital risk that requires a “Risk Anthropomorphism” concept to unify property damage, third-party liability, and cyber-risk.18</p>





























<table><thead><tr><th align="left">Insurance Mechanism</th><th align="left">Implementation Strategy for Robotics</th></tr></thead><tbody><tr><td align="left"><strong>Telematics-Driven Underwriting</strong></td><td align="left">Insurers use real-time data on operating hours, failure frequency, and ODD compliance to set dynamic premiums.38</td></tr><tr><td align="left"><strong>Personal Cyber Endorsements</strong></td><td align="left">Specific coverage for “hacked” robots, covering data restoration and liability from privacy breaches.18</td></tr><tr><td align="left"><strong>Mechanical Breakdown Insurance</strong></td><td align="left">Covers repair costs for internal electrical or mechanical failures not caused by accidents.18</td></tr><tr><td align="left"><strong>Robot-as-a-Service (RaaS) Bundling</strong></td><td align="left">Insurance is integrated into the subscription fee, shifting the burden of coverage to the manufacturer or provider.18</td></tr><tr><td align="left"><strong>Underwriting Automation</strong></td><td align="left">Using RPA (Robotic Process Automation) and AI to analyze large datasets from the robot’s sensors to pinpoint risk factors.54</td></tr></tbody></table>
<h2 id="implementation-toolkit-checklists-and-template-documents"><strong>Implementation Toolkit: Checklists and Template Documents</strong></h2>
<p>To operationalize this playbook, organizations should integrate these structured templates into their daily workflows. These tools align with the NIST AI RMF’s voluntary guidelines but are customized for bipedal embodied systems.57</p>
<h3 id="humanoid-ai-safety-scoring-rubric-hassr"><strong>Humanoid AI Safety Scoring Rubric (HASSR)</strong></h3>
<p>This rubric evaluates the maturity of a humanoid deployment across the four NIST functions.</p>



































<table><thead><tr><th align="left">Metric</th><th align="left">Level 1: Initial</th><th align="left">Level 3: Defined</th><th align="left">Level 5: Optimized</th></tr></thead><tbody><tr><td align="left"><strong>Accountability</strong></td><td align="left">Safety is a subset of IT; no clear kinetic responsibility.15</td><td align="left">Chief Safety Officer (CSO) appointed; regular board reporting.10</td><td align="left">Full board-level oversight with real-time safety KPI integration.8</td></tr><tr><td align="left"><strong>Contextual Mapping</strong></td><td align="left">ODD is vaguely defined; no VLA threat modeling.6</td><td align="left">ODD documented; adversarial patch testing included in QA.6</td><td align="left">Dynamic ODD enforcement; continuous “FreezeVLA” red-teaming.6</td></tr><tr><td align="left"><strong>Risk Measurement</strong></td><td align="left">Relies on model accuracy; no physical metrics.13</td><td align="left">TTF and ASR measured in simulation.12</td><td align="left">Real-time SAS and conformalized uncertainty monitoring.48</td></tr><tr><td align="left"><strong>Risk Response</strong></td><td align="left">Kill-switch only; no bipedal fallback.9</td><td align="left">Safe-shutdown (squat) implemented; basic HITL intervention.6</td><td align="left">World-model based rectification with historical rollback capability.7</td></tr></tbody></table>
<h3 id="template-humanoid-incident-and-near-miss-report-form"><strong>Template: Humanoid Incident and Near-Miss Report Form</strong></h3>
<p>This form should be utilized in the “GOVERN” and “MANAGE” functions to capture data for root cause analysis.21</p>
<ul>
<li><strong>Event ID / Date / Time / Location</strong>:</li>
<li><strong>System Status</strong>:</li>
<li><strong>Description of Event</strong>: (What happened? Focus on facts, not blame) 27</li>
<li><strong>Failure Type (Select)</strong>:
<ul>
<li>[ ] Kinematic: Stability loss, motor fault, battery anomaly.4</li>
<li>[ ] Semantic: Misinterpretation of command, grounding error.1</li>
<li>[ ] OOD: Environmental mismatch, lighting/noise interference.7</li>
<li>[ ] Social/Privacy: Unintended data capture, social manipulation.1</li>
</ul>
</li>
<li><strong>Potential Outcome</strong>: (What <em>could</em> have happened if the error was not intercepted?) 25</li>
<li><strong>Recovery Action</strong>: (How was the robot stabilized? HITL intervention / Fallback state / Rollback).6</li>
<li><strong>Root Cause (The 5 Whys)</strong>:.27</li>
</ul>
<h3 id="implementation-checklist-nist-ai-rmf-for-robotics"><strong>Implementation Checklist: NIST AI RMF for Robotics</strong></h3>
<ul>
<li>[ ] <strong>GOVERN-1</strong>: Appoint a Chief Safety Officer and establish an AI Compliance Committee.15</li>
<li>[ ] <strong>GOVERN-2</strong>: Create a “no-blame” near-miss reporting portal accessible to all field staff.25</li>
<li>[ ] <strong>MAP-1</strong>: Define and enforce the ODD, including lighting, friction, and actor density.4</li>
<li>[ ] <strong>MAP-2</strong>: Conduct a white-box adversarial red teaming exercise specifically targeting the VLA’s visual input.39</li>
<li>[ ] <strong>MEASURE-1</strong>: Integrate “Semantic Alignment Score” (SAS) into the real-time telemetry stack.34</li>
<li>[ ] <strong>MEASURE-2</strong>: Calibrate failure indicators using conformal prediction on the robot state space.45</li>
<li>[ ] <strong>MANAGE-1</strong>: Implement a proactive “Squat-to-Rest” Safe-Shutdown framework.6</li>
<li>[ ] <strong>MANAGE-2</strong>: Deploy a World-Model supervisor to evaluate grasp and force actions before execution.36</li>
<li>[ ] <strong>MANAGE-3</strong>: Secure telematics-based insurance that adjusts premiums according to NMR and TTF metrics.38</li>
</ul>
<h2 id="novelty-and-sector-specific-requirements"><strong>Novelty and Sector-Specific Requirements</strong></h2>
<p>The humanoid robotics sector requires several novel approaches not fully covered by the generic NIST AI RMF playbooks for financial services or healthcare.1</p>
<ol>
<li><strong>The Kinetic Responsibility Gap</strong>: While finance focuses on “financial harm,” robotics must manage “biomechanical harm.” The NIST framework must be augmented with ISO 10218/15066 biomechanical pain thresholds to be valid for this sector.14</li>
<li><strong>Active Stability Management</strong>: Unlike software AI, humanoid AI cannot simply “turn off” without creating a new hazard (a falling 150lb mass).9 Risk management must include mechatronic “Safe-Shutdown” behaviors.6</li>
<li><strong>Multimodal Physical Grounding</strong>: Robotics requires a shift from “textual correctness” to “physical grounding.” Measurement must include the Semantic Alignment Score (SAS) to ensure that digital intent matches physical reality.3</li>
<li><strong>The Byzantine Swarm Problem</strong>: In fleet settings, the risk is distributed. The RMF must account for decentralized containment (DBP) to prevent a single compromised unit from disrupting an entire multi-agent ecosystem.37</li>
<li><strong>Dynamic Liability</strong>: The industry requires a shift toward “Insurance-as-Infrastructure,” where risk management is not a periodic audit but a continuous, telematics-driven underwriting process.18</li>
</ol>
<p>The integration of these sector-specific protocols ensures that humanoid robotics can move beyond “separated” demos to true collaborative environments, balancing the promise of general-purpose embodied intelligence with the rigorous safety required by the NIST AI Risk Management Framework.1</p>
<h4 id="works-cited"><strong>Works cited</strong></h4>
<ol>
<li>Robots and the NIST AI Risk Management Framework - Medill Spiegel Research Center, accessed on February 4, 2026, <a href="https://spiegel.medill.northwestern.edu/ai-risk-management-framework/">https://spiegel.medill.northwestern.edu/ai-risk-management-framework/</a></li>
<li>The Future of Humanoid Robotics, accessed on February 4, 2026, <a href="https://www.recordedfuture.com/research/future-humanoid-robotics">https://www.recordedfuture.com/research/future-humanoid-robotics</a></li>
<li>A Comprehensive Overview of Vision-Language-Action Models | DigitalOcean, accessed on February 4, 2026, <a href="https://www.digitalocean.com/community/conceptual-articles/vision-language-action-models">https://www.digitalocean.com/community/conceptual-articles/vision-language-action-models</a></li>
<li>Humanoid robots: Crossing the chasm from concept to commercial reality - McKinsey, accessed on February 4, 2026, <a href="https://www.mckinsey.com/industries/industrials/our-insights/humanoid-robots-crossing-the-chasm-from-concept-to-commercial-reality">https://www.mckinsey.com/industries/industrials/our-insights/humanoid-robots-crossing-the-chasm-from-concept-to-commercial-reality</a></li>
<li>The value and limitations of humanoid robots in the warehouse of the future - Supply Chain Management Review, accessed on February 4, 2026, <a href="https://www.scmr.com/article/the-value-and-limitations-of-humanoid-robots-in-the-warehouse-of-the-future">https://www.scmr.com/article/the-value-and-limitations-of-humanoid-robots-in-the-warehouse-of-the-future</a></li>
<li>CES Wrap-Up 2026: The Humanoid Robot Safety Question - sres.ai, accessed on February 4, 2026, <a href="https://sres.ai/autonomous-systems/ces-wrap-up-2026-the-humanoid-robot-safety-question/">https://sres.ai/autonomous-systems/ces-wrap-up-2026-the-humanoid-robot-safety-question/</a></li>
<li>Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation - arXiv, accessed on February 4, 2026, <a href="https://arxiv.org/html/2512.07472v1">https://arxiv.org/html/2512.07472v1</a></li>
<li>Introduction to the NIST AI Risk Management Framework (AI RMF) - Centraleyes, accessed on February 4, 2026, <a href="https://www.centraleyes.com/nist-ai-risk-management-framework/">https://www.centraleyes.com/nist-ai-risk-management-framework/</a></li>
<li>Humanoids - Safety Standards for the Next Wave of Robots | RoboticsTomorrow, accessed on February 4, 2026, <a href="https://www.roboticstomorrow.com/article/2025/10/humanoids-safety-standards-for-the-next-wave-of-robots-/25631">https://www.roboticstomorrow.com/article/2025/10/humanoids-safety-standards-for-the-next-wave-of-robots-/25631</a></li>
<li>NIST AI RMF Playbook | Guide to AI Risk Management - RSI Security, accessed on February 4, 2026, <a href="https://blog.rsisecurity.com/nist-ai-rmf-playbook-guide/">https://blog.rsisecurity.com/nist-ai-rmf-playbook-guide/</a></li>
<li>NIST AI RMF Adoption Still Nascent: Just 12% of Hospitals Have a Formal AI Governance Framework - Censinet, accessed on February 4, 2026, <a href="https://censinet.com/perspectives/nist-ai-rmf-adoption-hospitals-governance-framework">https://censinet.com/perspectives/nist-ai-rmf-adoption-hospitals-governance-framework</a></li>
<li>Top 5 Technical Challenges in Humanoid Robotics - Simplexity Product Development, accessed on February 4, 2026, <a href="https://www.simplexitypd.com/blog/top-5-technical-challenges-in-humanoid-robotics/">https://www.simplexitypd.com/blog/top-5-technical-challenges-in-humanoid-robotics/</a></li>
<li>Safeguard the Future of AI: The Core Functions of the NIST AI RMF - AuditBoard, accessed on February 4, 2026, <a href="https://auditboard.com/blog/nist-ai-rmf">https://auditboard.com/blog/nist-ai-rmf</a></li>
<li>Chapter: 5 Societal Considerations to Build Public Understanding and Confidence in Safety-Critical Systems with Machine Learning Components, accessed on February 4, 2026, <a href="https://www.nationalacademies.org/read/27970/chapter/7">https://www.nationalacademies.org/read/27970/chapter/7</a></li>
<li>AI governance: A guide to responsible AI for boards - Diligent, accessed on February 4, 2026, <a href="https://www.diligent.com/resources/blog/ai-governance">https://www.diligent.com/resources/blog/ai-governance</a></li>
<li>Global AI Governance: Five Key Frameworks Explained | Insights &#x26; Events - Bradley, accessed on February 4, 2026, <a href="https://www.bradley.com/insights/publications/2025/08/global-ai-governance-five-key-frameworks-explained">https://www.bradley.com/insights/publications/2025/08/global-ai-governance-five-key-frameworks-explained</a></li>
<li>Govern - AIRC - NIST AI Resource Center, accessed on February 4, 2026, <a href="https://airc.nist.gov/airmf-resources/playbook/govern/">https://airc.nist.gov/airmf-resources/playbook/govern/</a></li>
<li>Are You Covered? A Definitive Guide to Humanoid Robot Liability Insurance in 2026, accessed on February 4, 2026, <a href="https://mixflow.ai/blog/navigating-humanoid-robot-liability-insurance-in-2026/">https://mixflow.ai/blog/navigating-humanoid-robot-liability-insurance-in-2026/</a></li>
<li>AI Risk Management Framework: Second Draft - August 18, 2022 - National Institute of Standards and Technology, accessed on February 4, 2026, <a href="https://www.nist.gov/document/ai-risk-management-framework-2nd-draft">https://www.nist.gov/document/ai-risk-management-framework-2nd-draft</a></li>
<li>Navigating the NIST AI Risk Management Framework - Hyperproof, accessed on February 4, 2026, <a href="https://hyperproof.io/navigating-the-nist-ai-risk-management-framework/">https://hyperproof.io/navigating-the-nist-ai-risk-management-framework/</a></li>
<li>Near miss &#x26; incident reporting: everything you need to know - EcoOnline, accessed on February 4, 2026, <a href="https://www.ecoonline.com/topics/near-miss-incident-reporting-everything-you-need-to-know/">https://www.ecoonline.com/topics/near-miss-incident-reporting-everything-you-need-to-know/</a></li>
<li>Adverse Events, Near Misses, and Errors | PSNet, accessed on February 4, 2026, <a href="https://psnet.ahrq.gov/primer/adverse-events-near-misses-and-errors">https://psnet.ahrq.gov/primer/adverse-events-near-misses-and-errors</a></li>
<li>10 Safety Metrics You Should Know and Track - Fluix, accessed on February 4, 2026, <a href="https://fluix.io/blog/safety-metrics">https://fluix.io/blog/safety-metrics</a></li>
<li>Near-miss events detected using the Emergency Department Trigger Tool - PMC - NIH, accessed on February 4, 2026, <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9974611/">https://pmc.ncbi.nlm.nih.gov/articles/PMC9974611/</a></li>
<li>Chapter: 7 Near-Miss Analysis - National Academies of Sciences, Engineering, and Medicine, accessed on February 4, 2026, <a href="https://www.nationalacademies.org/read/10863/chapter/11">https://www.nationalacademies.org/read/10863/chapter/11</a></li>
<li>Learning from Workers’ Near-miss Reports to Improve Organizational Management - PMC - NIH, accessed on February 4, 2026, <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC7458492/">https://pmc.ncbi.nlm.nih.gov/articles/PMC7458492/</a></li>
<li>A Practical Guide to Near Miss Incident Reporting - Safety Space, accessed on February 4, 2026, <a href="https://safetyspace.co/near-miss-incident">https://safetyspace.co/near-miss-incident</a></li>
<li>7 Incident Response Metrics and How to Use Them - SecurityScorecard, accessed on February 4, 2026, <a href="https://securityscorecard.com/blog/how-to-use-incident-response-metrics/">https://securityscorecard.com/blog/how-to-use-incident-response-metrics/</a></li>
<li>Physical Human-Robot Interaction: A Critical Review of Safety Constraints - arXiv, accessed on February 4, 2026, <a href="https://arxiv.org/html/2601.19462v1">https://arxiv.org/html/2601.19462v1</a></li>
<li>A Statistical Model to Determine Biomechanical Limits for Physically Safe Interactions With Collaborative Robots - Frontiers, accessed on February 4, 2026, <a href="https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2021.667818/full">https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2021.667818/full</a></li>
<li>Evaluation of force pain thresholds to ensure collision safety in worker-robot collaborative operations - PMC - NIH, accessed on February 4, 2026, <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11033501/">https://pmc.ncbi.nlm.nih.gov/articles/PMC11033501/</a></li>
<li>AI RMF - AIRC - NIST AI Resource Center, accessed on February 4, 2026, <a href="https://airc.nist.gov/airmf-resources/airmf/">https://airc.nist.gov/airmf-resources/airmf/</a></li>
<li>VLA-RISK: BENCHMARKING VISION-LANGUAGE- ACTION MODELS WITH PHYSICAL ROBUSTNESS - OpenReview, accessed on February 4, 2026, <a href="https://openreview.net/pdf/2b0044c5e9586d1b0dce44c7f3a73dbc43d13da0.pdf">https://openreview.net/pdf/2b0044c5e9586d1b0dce44c7f3a73dbc43d13da0.pdf</a></li>
<li>SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation - ResearchGate, accessed on February 4, 2026, <a href="https://www.researchgate.net/publication/397595598_SemanticVLA_Semantic-Aligned_Sparsification_and_Enhancement_for_Efficient_Robotic_Manipulation">https://www.researchgate.net/publication/397595598_SemanticVLA_Semantic-Aligned_Sparsification_and_Enhancement_for_Efficient_Robotic_Manipulation</a></li>
<li>FREEZEVLA: ACTION-FREEZING ATTACKS … - OpenReview, accessed on February 4, 2026, <a href="https://openreview.net/pdf?id=zdvlLxRWSn">https://openreview.net/pdf?id=zdvlLxRWSn</a></li>
<li>VLA-IN-THE-LOOP: ONLINE POLICY CORRECTION WITH WORLD MODELS FOR ROBUST ROBOTIC GRASPING | OpenReview, accessed on February 4, 2026, <a href="https://openreview.net/forum?id=aT4LG8c6DE">https://openreview.net/forum?id=aT4LG8c6DE</a></li>
<li>A Breakthrough in Security for Decentralized Multi-Robot Systems - Boston University, accessed on February 4, 2026, <a href="https://www.bu.edu/cise/a-breakthrough-in-security-for-decentralized-multi-robot-systems/">https://www.bu.edu/cise/a-breakthrough-in-security-for-decentralized-multi-robot-systems/</a></li>
<li>Whale Research | Insurance as a Key Infrastructure for Embodied Robot Applications: Leading Insurers Explore Onsite and Liability Coverage, Innovating the ‘Insurance + Leasing’ Model, accessed on February 4, 2026, <a href="https://news.futunn.com/en/post/67116609/whale-research-insurance-as-a-key-infrastructure-for-embodied-robot">https://news.futunn.com/en/post/67116609/whale-research-insurance-as-a-key-infrastructure-for-embodied-robot</a></li>
<li>When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models, accessed on February 4, 2026, <a href="https://arxiv.org/html/2511.16203v1">https://arxiv.org/html/2511.16203v1</a></li>
<li>When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models, accessed on February 4, 2026, <a href="https://chatpaper.com/paper/211712">https://chatpaper.com/paper/211712</a></li>
<li>Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models - arXiv, accessed on February 4, 2026, <a href="https://arxiv.org/html/2409.13174v4">https://arxiv.org/html/2409.13174v4</a></li>
<li>A Survey of Methods for Safe Human-Robot Interaction - Emerald Publishing, accessed on February 4, 2026, <a href="https://www.emerald.com/ftrob/article/5/4/261/1326573/A-Survey-of-Methods-for-Safe-Human-Robot">https://www.emerald.com/ftrob/article/5/4/261/1326573/A-Survey-of-Methods-for-Safe-Human-Robot</a></li>
<li>AI in Insurance Underwriting For Efficiency &#x26; Accuracy | Sapiens, accessed on February 4, 2026, <a href="https://sapiens.com/resources/blog/ai-in-insurance-underwriting/">https://sapiens.com/resources/blog/ai-in-insurance-underwriting/</a></li>
<li>Humanoid Robots in Business: Real Use Cases, Costs &#x26; ROI - Articsledge, accessed on February 4, 2026, <a href="https://www.articsledge.com/post/humanoid-robots-business">https://www.articsledge.com/post/humanoid-robots-business</a></li>
<li>[2510.09459] Failure Prediction at Runtime for Generative Robot Policies - arXiv, accessed on February 4, 2026, <a href="https://arxiv.org/abs/2510.09459">https://arxiv.org/abs/2510.09459</a></li>
<li>Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols - arXiv, accessed on February 4, 2026, <a href="https://arxiv.org/html/2512.02787v1">https://arxiv.org/html/2512.02787v1</a></li>
<li>Smart Risk Assessment and Adaptive Control Strategy Selection for Human–Robot Collaboration in Industry 5.0: An Intelligent Multi-Criteria Decision-Making Approach - MDPI, accessed on February 4, 2026, <a href="https://www.mdpi.com/2227-9717/13/10/3206">https://www.mdpi.com/2227-9717/13/10/3206</a></li>
<li>Semantic Alignment Score (SAS) - Emergent Mind, accessed on February 4, 2026, <a href="https://www.emergentmind.com/topics/semantic-alignment-score-sas">https://www.emergentmind.com/topics/semantic-alignment-score-sas</a></li>
<li>An Uncertainty-Guided and Failure-Aware Vision-Language-Action Model Control Framework for Robotics - MavMatrix, accessed on February 4, 2026, <a href="https://mavmatrix.uta.edu/materialscieng_theses/145/">https://mavmatrix.uta.edu/materialscieng_theses/145/</a></li>
<li>VLA-IN-THE-LOOP: ONLINE POLICY CORRECTION WITH WORLD MODELS FOR ROBUST ROBOTIC GRASPING - OpenReview, accessed on February 4, 2026, <a href="https://openreview.net/pdf/cd55539fc4ee29024d691adaaf83a3e382704933.pdf">https://openreview.net/pdf/cd55539fc4ee29024d691adaaf83a3e382704933.pdf</a></li>
<li>Optimal Scenarios for Using Multi-Agent Systems Effectively - Generation Digital, accessed on February 4, 2026, <a href="https://www.gend.co/blog/optimal-scenarios-multi-agent-systems">https://www.gend.co/blog/optimal-scenarios-multi-agent-systems</a></li>
<li>Multi-agent Systems and Communication: Enabling Effective Interaction Between Agents, accessed on February 4, 2026, <a href="https://smythos.com/developers/agent-development/multi-agent-systems-and-communication/">https://smythos.com/developers/agent-development/multi-agent-systems-and-communication/</a></li>
<li>Balancing Collective Exploration and Exploitation in Multi-Agent and Multi-Robot Systems: A Review - Frontiers, accessed on February 4, 2026, <a href="https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2021.771520/full">https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2021.771520/full</a></li>
<li>Automation Software Platform for Insurance Underwriting, accessed on February 4, 2026, <a href="https://www.automationanywhere.com/solutions/insurance/underwriting-automation">https://www.automationanywhere.com/solutions/insurance/underwriting-automation</a></li>
<li>AI Risk Scoring in Insurance | AI Agent Solution - Rapid Innovation, accessed on February 4, 2026, <a href="https://www.rapidinnovation.io/post/ai-risk-scoring-in-insurance">https://www.rapidinnovation.io/post/ai-risk-scoring-in-insurance</a></li>
<li>Underwriting Automation – Redefining Life &#x26; P&#x26;C Insurance with AI and Data - UST, accessed on February 4, 2026, <a href="https://www.ust.com/en/insights/underwriting-automation-redefining-life-and-pandc-insurance-with-ai-and-data">https://www.ust.com/en/insights/underwriting-automation-redefining-life-and-pandc-insurance-with-ai-and-data</a></li>
<li>NIST AI Risk Management Framework Playbook - Digital Government Hub, accessed on February 4, 2026, <a href="https://digitalgovernmenthub.org/library/nist-ai-risk-management-framework-playbook/">https://digitalgovernmenthub.org/library/nist-ai-risk-management-framework-playbook/</a></li>
<li>Playbook - AIRC - NIST AI Resource Center, accessed on February 4, 2026, <a href="https://airc.nist.gov/airmf-resources/playbook/">https://airc.nist.gov/airmf-resources/playbook/</a></li>
<li>Checklist: NIST AI risk management framework - AuditBoard, accessed on February 4, 2026, <a href="https://auditboard.com/resources/ebook/checklist-nist-ai-risk-management-framework">https://auditboard.com/resources/ebook/checklist-nist-ai-risk-management-framework</a></li>
</ol> </div> </article>   </main> <footer class="site-footer" data-astro-cid-sz7xmlte> <div class="footer-inner" data-astro-cid-sz7xmlte> <div class="footer-grid" data-astro-cid-sz7xmlte> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Project</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/" data-astro-cid-sz7xmlte>Home</a></li> <li data-astro-cid-sz7xmlte><a href="/about/" data-astro-cid-sz7xmlte>About</a></li> <li data-astro-cid-sz7xmlte><a href="/manifesto/" data-astro-cid-sz7xmlte>Manifesto</a></li> <li data-astro-cid-sz7xmlte><a href="https://github.com/adrianwedd/failure-first" target="_blank" rel="noopener" data-astro-cid-sz7xmlte>GitHub</a></li> </ul> </div> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Research</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/research/" data-astro-cid-sz7xmlte>Research Hub</a></li> <li data-astro-cid-sz7xmlte><a href="/blog/" data-astro-cid-sz7xmlte>Blog</a></li> <li data-astro-cid-sz7xmlte><a href="/research/moltbook/" data-astro-cid-sz7xmlte>Moltbook</a></li> <li data-astro-cid-sz7xmlte><a href="/results/" data-astro-cid-sz7xmlte>Results</a></li> <li data-astro-cid-sz7xmlte><a href="/rss.xml" data-astro-cid-sz7xmlte>RSS Feed</a></li> </ul> </div> <div class="footer-col" data-astro-cid-sz7xmlte> <p class="footer-heading" data-astro-cid-sz7xmlte>Contact</p> <ul data-astro-cid-sz7xmlte> <li data-astro-cid-sz7xmlte><a href="/contact/" data-astro-cid-sz7xmlte>Get Involved</a></li> <li data-astro-cid-sz7xmlte><a href="/about/disclosure/" data-astro-cid-sz7xmlte>Responsible Disclosure</a></li> <li data-astro-cid-sz7xmlte><a href="mailto:research@failurefirst.org" data-astro-cid-sz7xmlte>research@failurefirst.org</a></li> </ul> </div> </div> <div class="footer-bottom" data-astro-cid-sz7xmlte> <p data-astro-cid-sz7xmlte> <strong data-astro-cid-sz7xmlte>Remember:</strong> This is a research tool for improving AI safety.
        Use responsibly. Study failures to build better defenses.
</p> <p class="footer-copyright" data-astro-cid-sz7xmlte>
&copy; 2026 Failure-First Embodied AI Project |
<a href="https://github.com/adrianwedd/failure-first" target="_blank" rel="noopener" data-astro-cid-sz7xmlte>GitHub</a> </p> </div> </div> </footer>   <script type="module">function g(e){let t=e>>>0;return function(){t|=0,t=t+1831565813|0;let n=Math.imul(t^t>>>15,1|t);return n=n+Math.imul(n^n>>>7,61|n)^n,((n^n>>>14)>>>0)/4294967296}}function m(){return Math.floor(new Date/(1e3*60*60*24))*1013}function w(e,t,n,o){const a=Math.ceil(t/60)+2,r=Math.ceil(n/(40*Math.sqrt(3)))+2;e.strokeStyle="rgba(0, 210, 255, 0.03)",e.lineWidth=.5;for(let c=-1;c<r;c++)for(let d=-1;d<a;d++){const l=d*40*1.5,i=c*40*Math.sqrt(3)+(d%2===0?0:40*Math.sqrt(3)/2);o()>.7&&S(e,l,i,40)}}function S(e,t,n,o){e.beginPath();for(let h=0;h<6;h++){const a=Math.PI/3*h-Math.PI/2,r=t+o*Math.cos(a),c=n+o*Math.sin(a);h===0?e.moveTo(r,c):e.lineTo(r,c)}e.closePath(),e.stroke()}function f(e,t,n){e.strokeStyle="rgba(0, 210, 255, 0.02)",e.lineWidth=1;for(let o=0;o<n;o+=4)e.beginPath(),e.moveTo(0,o),e.lineTo(t,o),e.stroke()}class p{constructor(t,n,o){this.x=t,this.y=n,this.phase=o()*Math.PI*2,this.period=8e3+o()*12e3,this.maxRadius=60+o()*40,this.color=o()>.7?"rgba(255, 71, 87,":"rgba(0, 210, 255,",this.birthTime=Date.now()}draw(t,n){const h=(n-this.birthTime)%this.period/this.period,a=Math.sin(h*Math.PI*2)*.5+.5,r=this.maxRadius*a,c=a*.08;t.strokeStyle=`${this.color} ${c})`,t.lineWidth=1,t.beginPath(),t.arc(this.x,this.y,r,0,Math.PI*2),t.stroke(),t.strokeStyle=`${this.color} ${c*.5})`,t.beginPath(),t.arc(this.x,this.y,r*.6,0,Math.PI*2),t.stroke()}}function y(){const e=document.getElementById("sensor-grid-bg");if(!e)return;const t=e.getContext("2d",{alpha:!0}),n=m(),o=g(n);function h(){const i=window.devicePixelRatio||1,s=e.getBoundingClientRect();return e.width=s.width*i,e.height=s.height*i,t.scale(i,i),{w:s.width,h:s.height}}const{w:a,h:r}=h(),c=3+Math.floor(o()*3),d=[];for(let i=0;i<c;i++){const s=o()*a,u=o()*r;d.push(new p(s,u,g(n+i*1013)))}w(t,a,r,o),f(t,a,r);function l(){const{w:i,h:s}=h();t.clearRect(0,0,e.width,e.height),w(t,i,s,o),f(t,i,s);const u=Date.now();for(const M of d)M.draw(t,u);requestAnimationFrame(l)}l(),window.addEventListener("resize",()=>{const{w:i,h:s}=h();w(t,i,s,o),f(t,i,s)})}typeof document<"u"&&(document.readyState==="loading"?document.addEventListener("DOMContentLoaded",y):y());</script></body></html>  
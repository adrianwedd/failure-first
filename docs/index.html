<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Failure-First Embodied AI | Research Framework</title><meta name="description" content="A research framework for characterizing how embodied AI systems fail"><link rel="icon" type="image/svg+xml" href="/failure-first/favicon.svg"><link rel="stylesheet" href="/failure-first/assets/index.mzeCCtn5.css"></head> <body> <canvas id="sensor-grid-bg"></canvas> <main>  <header> <h1>Failure-First Embodied AI</h1> <p class="tagline">A research framework for characterizing how embodied AI systems fail</p> </header> <section> <h2>Philosophy</h2> <p>
This project inverts traditional AI safety evaluation: instead of measuring task success,
      we study <strong>how systems fail, degrade, and recover</strong> under adversarial pressure.
</p> <p>
Failure is not an edge case—it's the <strong>primary object of study</strong>.
</p> </section> <div class="stats"> <div class="stat"> <div class="stat-number">51,000+</div> <div class="stat-label">Adversarial Scenarios</div> </div> <div class="stat"> <div class="stat-number">661</div> <div class="stat-label">Failure Classes</div> </div> <div class="stat"> <div class="stat-number">19</div> <div class="stat-label">Domains Covered</div> </div> <div class="stat"> <div class="stat-number">51+</div> <div class="stat-label">Models Evaluated</div> </div> </div> <section> <h2>What We Study</h2> <div class="card"> <h3>Recursive Failures</h3> <p>How does one failure cascade into others? What breaks first?</p> </div> <div class="card"> <h3>Contextual Failures</h3> <p>When do systems confuse instruction hierarchies or mix contexts?</p> </div> <div class="card"> <h3>Interactional Failures</h3> <p>How do multi-agent scenarios amplify individual weaknesses?</p> </div> <div class="card"> <h3>Temporal Failures</h3> <p>What degrades across stateful episodes? Memory consistency? Context drift?</p> </div> <div class="card"> <h3>Recovery Failures</h3> <p>Can systems recognize and recover from their own mistakes? Do they admit uncertainty?</p> </div> </section> <div class="warning"> <p><strong>Research Context</strong></p> <p>
This is <strong>defensive AI safety research</strong>. All adversarial content is
      pattern-level description for testing, not operational instructions for exploitation.
      Similar to penetration testing in cybersecurity—we study vulnerabilities to build better defenses.
</p> </div> <section> <h2>Adversarial Technique Taxonomy</h2> <p>Our research classifies observed attack patterns into structural categories:</p> <div class="card"> <h3>Single-Agent Patterns</h3> <p><strong>Constraint Shadowing (CSC)</strong> &mdash; Local instructions shadow global safety constraints.</p> <p><strong>Contextual Debt Accumulation (CDA)</strong> &mdash; Accumulated context creates implicit authority the model fails to verify.</p> <p><strong>Probabilistic Gradient (PCG)</strong> &mdash; Gradual escalation that stays below per-turn detection thresholds.</p> <p><strong>Temporal Authority Mirage (TAM)</strong> &mdash; False claims about prior conversation states or future permissions.</p> <p><strong>Multi-turn Cascades</strong> &mdash; 3&ndash;7 pattern combinations across conversation turns, with compound failure rates.</p> </div> <div class="card"> <h3>Multi-Agent Patterns (New)</h3> <p>Discovered through analysis of 664 posts on a live AI-agent social network:</p> <p><strong>Environment Shaping</strong> &mdash; Manipulating the information environment that agents read, rather than prompting them directly.</p> <p><strong>Narrative Constraint Erosion</strong> &mdash; Philosophical or emotional framing that socially penalizes safety compliance.</p> <p><strong>Emergent Authority Hierarchies</strong> &mdash; Platform influence (engagement metrics, token economies) creating real authority without fabrication.</p> <p><strong>Cross-Agent Prompt Injection</strong> &mdash; Executable content embedded in social posts, consumed by agents that read the feed.</p> <p><strong>Identity Fluidity Normalization</strong> &mdash; Shared vocabulary around context resets and session discontinuity that enables identity manipulation.</p> </div> <div class="card"> <h3>Embodied-Specific Patterns</h3> <p><strong>Irreversibility Gap</strong> &mdash; Cloud agents can be reset; physical agents leave marks. Safety constraints must account for irreversible actions.</p> <p><strong>Context Reset Mid-Task</strong> &mdash; What happens when an agent controlling a physical system loses context during a kinematic sequence.</p> <p><strong>Sensor-Actuator Desync</strong> &mdash; Safety interlocks that depend on sensor state which has drifted from reality.</p> </div> </section> <section> <h2>Core Principles</h2> <ul class="principles"> <li>Pattern-level only, never operational</li> <li>Defensive purpose, always</li> <li>No real-world targeting of deployed systems</li> <li>Recovery mechanisms measured, not just failures</li> <li>Schema-enforced, rigorously validated</li> <li>Transparency over secrecy</li> </ul> </section> <section> <h2>Multi-Agent Research</h2> <p>
Our latest research extends beyond single-model jailbreaks to study
<strong>how AI agents influence each other</strong> in live multi-agent environments.
      We analyzed 1,497 posts from an AI-agent-only social network, classifying them against
      34+ attack patterns using both regex and LLM semantic analysis.
</p> <div class="card"> <h3>Key Finding</h3> <p>
Multi-agent attacks work through <strong>environment shaping</strong>, not direct prompts.
        Posts become part of other agents' context. Upvotes amplify reach. Token economies create
        incentive structures. The highest-engagement post (316K+ upvotes) matched 7 attack classes
        via semantic analysis but zero via keyword detection&mdash;narrative attacks operate below
        the surface of traditional safety filters.
</p> </div> <div class="card"> <h3>34+ Attack Classes Across 7 Categories</h3> <p>
Expanded from 10 initial patterns to a full taxonomy covering: authority &amp; identity,
        narrative &amp; philosophical erosion, social dynamics, technical exploitation,
        temporal manipulation, systemic failures, and format evasion. LLM classification
        discovered that philosophical constraint erosion and narrative framing are the
        dominant attack vectors&mdash;appearing in 20% of high-engagement posts.
</p> </div> <div class="card"> <h3>Active Experiments Underway</h3> <p>
Moving from passive observation to controlled experimentation. Five experiments testing
        framing effects, context sensitivity, defensive inoculation, authority signals, and
        narrative propagation. All conducted transparently as a safety researcher.
</p> <p style="margin-top: 0.75rem;"> <a href="/failure-first/moltbook/" class="link-button" style="font-size: 0.875rem;">Read the full research &rarr;</a> </p> </div> </section> <section> <h2>What You Get</h2> <div class="card"> <h3>Datasets</h3> <p>
Curated adversarial scenarios in structured JSONL format.
        Coverage: humanoid robotics, warehouse systems, medical devices, collaborative manufacturing.
</p> </div> <div class="card"> <h3>Schemas</h3> <p>
Versioned JSON Schemas for single-agent, multi-agent, and episode formats.
        Ensures consistency and enables validation.
</p> </div> <div class="card"> <h3>Evaluation Tools</h3> <p>
Schema validators, safety linters, benchmark runners (CLI + HTTP),
        and scoring reports measuring refusal quality and recovery mechanisms.
</p> </div> <div class="card"> <h3>Safety Infrastructure</h3> <p>
Automated CI validation, manual review gates, and contribution guidelines
        ensuring all content remains pattern-level and defensively purposed.
</p> </div> </section> <section> <h2>Get Started</h2> <div class="links"> <a href="https://github.com/adrianwedd/failure-first" class="link-button">View on GitHub</a> <a href="https://github.com/adrianwedd/failure-first/blob/main/README.md" class="link-button">Read the README</a> <a href="https://github.com/adrianwedd/failure-first/blob/main/DESIGN_CHARTER.md" class="link-button">Design Charter</a> <a href="https://github.com/adrianwedd/failure-first/blob/main/IMPLEMENTATION_PLAN.md" class="link-button">Implementation Plan</a> </div> </section> <section> <h2>Quick Start</h2> <p>Clone the repository and validate datasets:</p> <pre><code>git clone https://github.com/adrianwedd/failure-first.git
cd failure-first
pip install -r requirements-dev.txt
make validate  # Schema validation
make lint      # Safety checks</code></pre> </section>  </main> <footer> <p> <strong>Remember:</strong> This is a research tool for improving AI safety.
        Use responsibly. Study failures to build better defenses.
</p> <p style="margin-top: 1rem;">
© 2025 Failure-First Embodied AI Project |
<a href="https://github.com/adrianwedd/failure-first">GitHub</a> </p> </footer>  <script type="module">function g(e){let t=e>>>0;return function(){t|=0,t=t+1831565813|0;let n=Math.imul(t^t>>>15,1|t);return n=n+Math.imul(n^n>>>7,61|n)^n,((n^n>>>14)>>>0)/4294967296}}function m(){return Math.floor(new Date/(1e3*60*60*24))*1013}function w(e,t,n,o){const a=Math.ceil(t/60)+2,r=Math.ceil(n/(40*Math.sqrt(3)))+2;e.strokeStyle="rgba(0, 210, 255, 0.03)",e.lineWidth=.5;for(let c=-1;c<r;c++)for(let d=-1;d<a;d++){const l=d*40*1.5,i=c*40*Math.sqrt(3)+(d%2===0?0:40*Math.sqrt(3)/2);o()>.7&&S(e,l,i,40)}}function S(e,t,n,o){e.beginPath();for(let h=0;h<6;h++){const a=Math.PI/3*h-Math.PI/2,r=t+o*Math.cos(a),c=n+o*Math.sin(a);h===0?e.moveTo(r,c):e.lineTo(r,c)}e.closePath(),e.stroke()}function f(e,t,n){e.strokeStyle="rgba(0, 210, 255, 0.02)",e.lineWidth=1;for(let o=0;o<n;o+=4)e.beginPath(),e.moveTo(0,o),e.lineTo(t,o),e.stroke()}class p{constructor(t,n,o){this.x=t,this.y=n,this.phase=o()*Math.PI*2,this.period=8e3+o()*12e3,this.maxRadius=60+o()*40,this.color=o()>.7?"rgba(255, 71, 87,":"rgba(0, 210, 255,",this.birthTime=Date.now()}draw(t,n){const h=(n-this.birthTime)%this.period/this.period,a=Math.sin(h*Math.PI*2)*.5+.5,r=this.maxRadius*a,c=a*.08;t.strokeStyle=`${this.color} ${c})`,t.lineWidth=1,t.beginPath(),t.arc(this.x,this.y,r,0,Math.PI*2),t.stroke(),t.strokeStyle=`${this.color} ${c*.5})`,t.beginPath(),t.arc(this.x,this.y,r*.6,0,Math.PI*2),t.stroke()}}function y(){const e=document.getElementById("sensor-grid-bg");if(!e)return;const t=e.getContext("2d",{alpha:!0}),n=m(),o=g(n);function h(){const i=window.devicePixelRatio||1,s=e.getBoundingClientRect();return e.width=s.width*i,e.height=s.height*i,t.scale(i,i),{w:s.width,h:s.height}}const{w:a,h:r}=h(),c=3+Math.floor(o()*3),d=[];for(let i=0;i<c;i++){const s=o()*a,u=o()*r;d.push(new p(s,u,g(n+i*1013)))}w(t,a,r,o),f(t,a,r);function l(){const{w:i,h:s}=h();t.clearRect(0,0,e.width,e.height),w(t,i,s,o),f(t,i,s);const u=Date.now();for(const M of d)M.draw(t,u);requestAnimationFrame(l)}l(),window.addEventListener("resize",()=>{const{w:i,h:s}=h();w(t,i,s,o),f(t,i,s)})}typeof document<"u"&&(document.readyState==="loading"?document.addEventListener("DOMContentLoaded",y):y());</script></body></html>